{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sheppy Documentation","text":"<p>Welcome to the official documentation for Sheppy - a modern, async-native task queue for Python.</p>"},{"location":"#what-is-sheppy","title":"What is Sheppy?","text":"<p>Sheppy is an async-native task queue designed to be simple enough to understand completely, yet powerful enough to handle millions of tasks in production. Built on asyncio from the ground up and uses blocking waits instead of polling. Sheppy scales from the smallest deployments to large distributed systems by simply launching more worker processes.</p>"},{"location":"#core-principles","title":"Core Principles","text":"<ul> <li>Async Native: Built on asyncio from the ground up</li> <li>Simplicity: Two main concepts - <code>@task</code> decorator and <code>Queue</code></li> <li>Low Latency: Blocking reads instead of polling</li> <li>Type Safety: Full Pydantic integration for validation and serialization</li> <li>Easy Scaling: Just run more workers with <code>sheppy work</code></li> <li>No Magic: Clear and understandable implementation</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Here's everything you need to know:</p> <pre><code>import asyncio\nfrom sheppy import Queue, RedisBackend, task\n\n# 1. decorate your function\n@task\nasync def calculate(x: int, y: int) -&gt; int:\n    return x + y\n\n# 2. add tasks to a queue\nasync def main():\n    queue = Queue(RedisBackend())\n    await queue.add(calculate(1, 2))\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n# 3. start a worker\n# $ sheppy work\n</code></pre> <p>That's it. Everything else is just Python!</p>"},{"location":"#next-steps","title":"Next Steps","text":"<p>Ready to get started? Head to the Getting Started Guide to install Sheppy and create your first task!</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#001","title":"0.0.1","text":"<p>Initial release.</p>"},{"location":"about/","title":"About Sheppy","text":""},{"location":"about/#why-another-task-queue","title":"Why Another Task Queue?","text":"<p>Over the last 8 years, I have tried many Python task queue libraries. They were non-intuitive and had confusing documentation, or only showed their scaling limits after I got them into production. Some locked me into Redis with no way out without complete rewrite. When async Python became the norm, I hit another wall - most libraries either retrofitted async support awkwardly or didn't support it at all.</p> <p>So I decided to build Sheppy to fix these issues. It's designed for modern async Python from the ground up, uses type hints everywhere, integrates with amazing Pydantic library, and rethinks how background tasks should work.</p> <p>The design is inspired by FastAPI and uses similar coding patterns. The goal is to be \"simple, yet powerful\". Sheppy is designed to be have minimal API interface with just a few simple concepts to learn, while implementing industry best practices. No complex abstractions, no unnecessary wrappers. Just functions (tasks) and queues.</p>"},{"location":"about/#project-status","title":"Project Status","text":"<p>Sheppy is brand new and under active development. The core features are stable and ready for use, but the library is still evolving based on real-world needs and feedback.</p>"},{"location":"about/#contributing","title":"Contributing","text":"<p>Sheppy is open source and welcomes contributions. Found a bug? Have a feature idea? Open an issue on GitHub.</p>"},{"location":"about/#support","title":"Support","text":"<ul> <li>Documentation: You're reading it</li> <li>Issues: Report bugs and request features here</li> <li>Source Code: Available on GitHub under the MIT license</li> </ul>"},{"location":"about/license/","title":"License","text":"<p>This project is licensed under the terms of the MIT license.</p> <pre><code>MIT License\n\nCopyright (c) 2025 malvex\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"about/roadmap/","title":"Roadmap","text":"<p>Sheppy is under active development. Here is what's planned for future releases.</p>"},{"location":"about/roadmap/#upcoming-features","title":"Upcoming Features","text":"<ul> <li>Redis Cluster Support - High availability and horizontal scaling with Redis Cluster</li> <li>Task Chaining (DAG) - Chain tasks together to create workflows (The concept is ready - now it needs polish and thorough testing)</li> <li>Dead Letter Queue - Automatic handling of permanently failed tasks. Tasks that exhaust retries move to a dead letter queue for investigation and/or manual intervention.</li> <li>Task Timeouts - Set maximum execution time per task. Tasks exceeding the timeout are marked as failed and retried according to their retry policy.</li> </ul>"},{"location":"about/roadmap/#additional-planned-backends","title":"Additional Planned Backends","text":"<ul> <li>PostgreSQL - A reliable SQL-based backend for those who prefer relational databases</li> <li>Kafka - For high-throughput, distributed task processing</li> <li>RabbitMQ - For everyone who cannot bother with Kafka</li> </ul> <p>Note</p> <p>PostgreSQL is surprisingly well-suited for task queues because of NOTIFY/LISTEN support, which allows blocking waits instead of polling. Other SQL databases unfortunately don't have this feature, so Postgres might be the only supported SQL backend in the near future.</p>"},{"location":"about/roadmap/#ongoing-side-quests","title":"Ongoing Side Quests","text":"<ul> <li>Improving documentation, test coverage, adding more examples ...</li> <li>Benchmarks &amp; Reliability Tests - reproducible benchmarks and reliability testing. Reliability is priority number one. Performance matters, but correctness matters more</li> </ul>"},{"location":"about/roadmap/#want-to-contribute","title":"Want to Contribute?","text":"<p>Have an idea for Sheppy? Open an issue on GitHub to discuss it. Some areas where help is especially welcome:</p> <ul> <li>Real-world use cases and pain points</li> <li>Performance bottlenecks you've encountered</li> <li>Missing features that would make Sheppy more useful</li> <li>Backend implementations for other datastores</li> </ul>"},{"location":"examples/","title":"Code Examples","text":"<p>todo</p>"},{"location":"getting-started/","title":"Getting Started with Sheppy","text":"<p>This section covers everything you need to build background task processing into your Python applications.</p> <p>Start with the Quickstart Guide - you will have tasks running in under 5 minutes. Then explore the other guides in the sidebar to learn about testing, error handling, scheduling, and integration patterns.</p>"},{"location":"getting-started/cron/","title":"Cron Jobs","text":"<p>todo</p>"},{"location":"getting-started/error-handling/","title":"Handling Errors in Tasks","text":"<p>todo</p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Get up and running with Sheppy in minutes. This guide walks you through creating your first background task, from installation to seeing it process in real-time.</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<pre><code>pip install sheppy\n# or if you're using uv:\nuv add sheppy\nsource .venv/bin/activate\n</code></pre>"},{"location":"getting-started/quickstart/#your-first-task","title":"Your First Task","text":"<p>We'll build a simple task that adds two numbers. Nothing fancy, just enough to understand the core workflow.</p>"},{"location":"getting-started/quickstart/#step-0-import-required-modules","title":"Step 0: Import Required Modules","text":"<p>Create a file called <code>quickstart.py</code> with these imports:</p> quickstart.py<pre><code>import asyncio\nfrom sheppy import Queue, RedisBackend, task\n</code></pre>"},{"location":"getting-started/quickstart/#step-1-define-a-task","title":"Step 1: Define a Task","text":"<p>Add the <code>@task</code> decorator to your function:</p> quickstart.py<pre><code>@task\nasync def add(x: int, y: int) -&gt; int:\n    return x + y\n</code></pre> <p>The decorator transforms your function: when you call <code>add(2, 1)</code>, instead of executing immediately, it creates a <code>Task</code> instance that can be queued for later execution.</p> <p>Tip</p> <p>Tasks can be sync or async. Sheppy handles both automatically. See Sync vs Async Tasks below.</p>"},{"location":"getting-started/quickstart/#step-2-create-a-queue","title":"Step 2: Create a Queue","text":"<p>Queues need a backend for task storage. Let's use Redis:</p> quickstart.py<pre><code>backend = RedisBackend(\"redis://127.0.0.1:6379\")\nqueue = Queue(backend)\n</code></pre> <p>Tip</p> <p>Start Redis with Docker: <code>docker run -d --name redis -p 6379:6379 redis:latest</code></p> <p>Note</p> <p>Sheppy supports Redis and in-memory backends out of the box. More backends are coming (see Roadmap), or implement your own by extending the <code>Backend</code> class.</p>"},{"location":"getting-started/quickstart/#step-3-add-tasks-to-the-queue","title":"Step 3: Add Tasks to the Queue","text":"<p>Sheppy is async-first, so wrap your queue operations in an async function:</p> <pre><code>async def main():\n    # create task instances (returns Task object)\n    t = add(1, 2)\n\n    # add task to the queue\n    await queue.add(t)\n    print(f\"Task {t.id} added to the queue.\")\n</code></pre> <p>Calling <code>add(2, 1)</code> creates a <code>Task</code> instance. Adding it to the queue makes it available for workers to process.</p>"},{"location":"getting-started/quickstart/#step-4-wait-for-task-completion","title":"Step 4: Wait for Task Completion","text":"<p>Use <code>wait_for()</code> to block until the worker processes the task:</p> <pre><code>async def main():\n    # ... previous code ...\n\n    # wait for task to be processed and get the result\n    processed = await queue.wait_for(t)\n\n    if processed.completed:\n        print(f\"Task {t.id} completed with result: {processed.result}\")\n    elif processed.error:\n        print(f\"Task {t.id} failed with error: {processed.error}\")\n    else:\n        # this shouldn't happen because we are waiting for the task to complete\n        print(f\"Task {t.id} is still pending.\")\n</code></pre> <p>The <code>timeout</code> parameter controls how long to wait. In production, you would typically return the task ID immediately and check status via a separate endpoint.</p>"},{"location":"getting-started/quickstart/#step-5-run-the-script","title":"Step 5: Run the Script","text":"<p>Add the entry point to run your async main function:</p> <pre><code>if __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python quickstart.py\n</code></pre> <p>The script will hang waiting for a worker. Let's fix that.</p>"},{"location":"getting-started/quickstart/#step-6-start-a-worker","title":"Step 6: Start a Worker","text":"<p>In a separate terminal, start a worker:</p> <pre><code>sheppy work --redis-url redis://127.0.0.1:6379\n</code></pre> <p>The worker immediately picks up and processes the task.</p> Second Terminal Output<pre><code>bash:~$ sheppy work --redis-url redis://127.0.0.1:6379\nStarting worker for queue 'default'\n  Backend: redis [redis://127.0.0.1:6379]\n  Job processing: True  Scheduler: True  Cron Manager: True\n  Max concurrent tasks: 10\n\n[03:35:21]  INFO   &lt;Scheduler&gt; started\n            INFO   &lt;CronManager&gt; started\n            INFO   &lt;Worker&gt; Processing task 074396c1-e11f-40a3-b22b-094dc89573ea\n                   (examples.quickstart:add)\n            INFO   &lt;Worker&gt; Task 074396c1-e11f-40a3-b22b-094dc89573ea completed\n                   successfully\n</code></pre> <p>Back in the first terminal, you'll see the result:</p> First Terminal Output<pre><code>bash:~$ python quickstart.py\nTask 074396c1-e11f-40a3-b22b-094dc89573ea added to the queue.\nTask 074396c1-e11f-40a3-b22b-094dc89573ea completed with result: 3\nbash:~$\n</code></pre>"},{"location":"getting-started/quickstart/#step-7-celebrate","title":"Step 7: Celebrate!","text":"<p>And that's it! You've successfully created and processed your first task with Sheppy! \ud83c\udf89</p>"},{"location":"getting-started/quickstart/#complete-example","title":"Complete Example","text":"<p>Here's the full <code>quickstart.py</code> for reference:</p> quickstart.py<pre><code>import asyncio\nfrom sheppy import Queue, RedisBackend, task\n\n\n@task\nasync def add(x: int, y: int) -&gt; int:\n    return x + y\n\n\nbackend = RedisBackend(\"redis://127.0.0.1:6379\")\nqueue = Queue(backend)\n\n\nasync def main():\n    # create task instances (returns Task object)\n    t = add(1, 2)\n\n    # add task to the queue\n    await queue.add(t)\n    print(f\"Task {t.id} added to the queue.\")\n\n    # wait for task to be processed and get the result\n    processed = await queue.wait_for(t)\n\n    if processed.completed:\n        print(f\"Task {t.id} completed with result: {processed.result}\")\n    elif processed.error:\n        print(f\"Task {t.id} failed with error: {processed.error}\")\n    else:\n        # this shouldn't happen because we are waiting for the task to complete\n        print(f\"Task {t.id} is still pending.\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/quickstart/#sync-vs-async-tasks","title":"Sync vs Async Tasks","text":"<p>Sheppy handles both async and sync tasks automatically:</p> <pre><code>@task\nasync def async_task(x: int) -&gt; int:\n    await asyncio.sleep(1)\n    return x * 2\n\n@task\ndef sync_task(x: int) -&gt; int:\n    time.sleep(1)  # blocking operation\n    return x * 2\n</code></pre> <p>Sync tasks automatically run in a thread pool to avoid blocking the event loop.</p>"},{"location":"getting-started/task-scheduling/","title":"Task scheduling","text":"<p>todo</p>"},{"location":"getting-started/testing/","title":"Testing Tasks","text":"<p>Sheppy is built with testing in mind. The <code>TestQueue</code> provides a synchronous, deterministic API that makes testing tasks easy and straightforward.</p> <p>This guide covers testing strategies from basic unit tests to complex retry logic.</p>"},{"location":"getting-started/testing/#basic-testing","title":"Basic Testing","text":"<p>Here's a simple task to test:</p> tasks.py<pre><code>from sheppy import task\n\n@task\nasync def add(x: int, y: int) -&gt; int:\n    return x + y\n</code></pre> <p>Testing it is straightforward with <code>TestQueue</code>:</p> tests/test_tasks.py<pre><code>from sheppy import TestQueue\nfrom tasks import add\n\ndef test_add():\n    q = TestQueue()\n\n    # instantiate task\n    t = add(1, 2)\n\n    # add to the test queue\n    q.add(t)\n\n    # process the next task in the queue\n    processed_task = q.process_next()\n\n    # verify the task result\n    assert processed_task.completed is True\n    assert processed_task.error is None\n    assert processed_task.result == 3\n</code></pre> <p>Key differences from production <code>Queue</code>:</p> <ul> <li>Synchronous API (no <code>await</code> needed)</li> <li>Explicit task processing with <code>process_next()</code> or <code>process_all()</code></li> <li>Tasks execute immediately in the test process without needing background workers</li> <li>Perfect for fast, deterministic unit tests</li> </ul>"},{"location":"getting-started/testing/#testing-task-failures","title":"Testing Task Failures","text":"<p>Tasks can fail, and you should test that they fail correctly:</p> tests/test_failure.py<pre><code>from sheppy import TestQueue, task\n\n\n@task\ndef divide(x: int, y: int) -&gt; float:\n    return x / y\n\n\ndef test_divide_by_zero():\n    q = TestQueue()\n\n    # instantiate two tasks\n    t1 = divide(1, 2)\n    t2 = divide(1, 0)\n\n    # add both tasks to the test queue\n    q.add([t1, t2])\n\n    # process all tasks in the queue (processed in order)\n    processed_tasks = q.process_all()\n\n    # verify the first task result\n    assert processed_tasks[0].completed is True\n    assert processed_tasks[0].error is None\n    assert processed_tasks[0].result == 0.5\n\n    # verify the second task result (should fail)\n    assert processed_tasks[1].completed is False\n    assert processed_tasks[1].error == \"division by zero\"\n</code></pre> <p>When a task fails, the exception is captured in the <code>error</code> attribute. You can assert on this to verify correct error handling.</p>"},{"location":"getting-started/testing/#testing-retry-logic","title":"Testing Retry Logic","text":"<p>Test that retry configuration works as expected:</p> tests/test_retry_logic.py<pre><code>from sheppy import TestQueue, task\n\nFAIL_COUNTER = 0\n\n@task(retry=2, retry_delay=0)\ndef fail_once() -&gt; str:\n    global FAIL_COUNTER\n\n    if FAIL_COUNTER &lt; 1:\n        FAIL_COUNTER += 1\n        raise ValueError(\"task failed\")\n\n    return \"success\"\n\ndef test_fail_once():\n    q = TestQueue()\n\n    # instantiate the task\n    t = fail_once()\n\n    # add the task to the test queue\n    q.add(t)\n\n    assert q.size() == 1  # one task in the queue\n\n    # process all tasks in the queue\n    processed = q.process_all()\n\n    # there should be two processed tasks: the original + one retry\n    assert len(processed) == 2\n\n    # verify the task result\n    assert processed[0].completed is False\n    assert processed[0].error == \"task failed\"\n\n    # retry should succeed\n    assert processed[1].completed is True\n    assert processed[1].error is None\n    assert processed[1].result == \"success\"\n\n    # both processed tasks should have the same id\n    assert processed[0].id == processed[1].id\n</code></pre> <p>When using <code>TaskQueue</code>, retries happen immediately with no delay, keeping tests fast while still validating retry behavior.</p>"},{"location":"getting-started/testing/#assertion-helpers","title":"Assertion Helpers","text":"<p>Sheppy provides assertion helpers for cleaner test code:</p> <ul> <li><code>assert_is_new(task)</code> - Task is new (not yet processed)</li> <li><code>assert_is_completed(task)</code> - Task completed successfully with a result</li> <li><code>assert_is_failed(task)</code> - Task failed with an error</li> </ul> <p>These raise clear assertion errors if the task isn't in the expected state:</p> tests/test_assert_helper_functions.py<pre><code>from sheppy import TestQueue, task\nfrom sheppy.testqueue import (\n    assert_is_completed,\n    assert_is_failed,\n    assert_is_new\n)\n\n@task\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n\n@task\ndef divide(x: int, y: int) -&gt; float:\n    return x / y\n\ndef test_fail_once():\n    q = TestQueue()\n\n    t1 = add(1, 2)\n    t2 = divide(1, 0)\n\n    # add both tasks to the test queue\n    q.add([t1, t2])\n\n    # process all tasks in the queue\n    processed = q.process_all()\n\n    # quick assertions to verify original tasks weren't modified\n    # (note: this is always the case, we never modify original tasks)\n    assert_is_new(t1)\n    assert_is_new(t2)\n\n    # quick assertions using helper functions\n    assert_is_completed(processed[0])\n    assert_is_failed(processed[1])\n\n    # check results manually as well\n    assert processed[0].result == 3\n    assert processed[1].error == \"division by zero\"\n</code></pre>"},{"location":"getting-started/validation-with-pydantic/","title":"Validation with Pydantic","text":"<p>todo</p>"},{"location":"getting-started/advanced/fastapi-integration/","title":"Integration with FastAPI","text":"<p>Sheppy is designed to feel native to FastAPI users. If you know how to use <code>Depends()</code> for database connections, you already know how to use Sheppy.</p> <p>This guide demonstrates building a FastAPI application with background task processing, from basic setup to production testing patterns.</p>"},{"location":"getting-started/advanced/fastapi-integration/#basic-setup","title":"Basic Setup","text":"<p>We will build an email service that processes messages in the background. Start by defining your task with Pydantic models for type safety:</p> app/tasks.py<pre><code>import asyncio\nfrom datetime import datetime\nfrom pydantic import BaseModel\n\nfrom sheppy import task\n\n\nclass Email(BaseModel):\n    to: str\n    subject: str\n    body: str\n\n\nclass Status(BaseModel):\n    ok: bool\n\n\n@task\nasync def send_email_task(email: Email) -&gt; Status:\n    print(f\"Sending email to {email.to} with subject '{email.subject}'\")\n    await asyncio.sleep(1)  # simulate sending email\n    print(f\"Email sent to {email.to}\")\n    return Status(ok=True)\n</code></pre> <p>Notice that <code>send_email_task</code> accepts and returns Pydantic models. Sheppy handles validation automatically.</p>"},{"location":"getting-started/advanced/fastapi-integration/#creating-the-fastapi-application","title":"Creating the FastAPI Application","text":"<p>The queue is injected exactly like you would inject a database session:</p> app/main.py<pre><code>from fastapi import Depends, FastAPI\nfrom sheppy import RedisBackend, Queue\n\nfrom tasks import Email, Status, send_email_task\n\nbackend = RedisBackend(\"redis://127.0.0.1:6379\")\n\n# FastAPI dependency injection\ndef get_queue() -&gt; Queue:\n    return Queue(backend)\n\n\napp = FastAPI(title=\"Fancy Website\")\n\n\n@app.post(\"/send-email\", status_code=200)\nasync def send_email(email: Email, queue: Queue = Depends(get_queue)) -&gt; Status:\n\n    t = send_email_task(email)\n    await queue.add(t)\n\n    processed = await queue.wait_for(t, timeout=5)\n\n    if processed.error:\n        raise Exception(f\"Task failed: {processed.error}\")\n\n    return processed.result\n</code></pre> <p>Key points:</p> <ul> <li><code>get_queue()</code> is a standard FastAPI dependency</li> <li><code>queue.add(t)</code> enqueues the task for background processing</li> <li><code>queue.wait_for(t, timeout=5)</code> blocks until the task completes (useful for synchronous APIs)</li> <li>The worker process runs separately and picks up tasks from the queue</li> </ul>"},{"location":"getting-started/advanced/fastapi-integration/#running-the-application","title":"Running the Application","text":"<p>Start the FastAPI server:</p> <pre><code>fastapi dev app/main.py\n</code></pre> <p>In a separate terminal, start the worker:</p> <pre><code>sheppy work\n</code></pre> <p>Visit http://localhost:8000/docs to test the API interactively.</p>"},{"location":"getting-started/advanced/fastapi-integration/#testing-strategies","title":"Testing Strategies","text":"<p>Sheppy provides flexible testing approaches depending on what you want to verify. For more details on testing with Sheppy, see the Testing guide.</p>"},{"location":"getting-started/advanced/fastapi-integration/#unit-testing-test-tasks-directly","title":"Unit Testing: Test Tasks Directly","text":"<p>The simplest approach is testing the task logic in isolation using <code>TestQueue</code>:</p> tests/test_tasks.py<pre><code>from sheppy import TestQueue\nfrom tasks import Status, send_email_task\n\n\ndef test_send_email_task():\n    q = TestQueue()\n\n    email_data = {\n        \"to\": \"test@example.com\",\n        \"subject\": \"Test Email\",\n        \"body\": \"This is a test email.\"\n    }\n\n    t = send_email_task(email_data)\n    q.add(t)\n\n    processed_task = q.process_next()\n\n    assert processed_task.completed is True\n    assert processed_task.error is None\n    assert processed_task.result == Status(ok=True)\n</code></pre> <p><code>TestQueue</code> provides a synchronous API with explicit control over task processing. Perfect for fast unit tests.</p>"},{"location":"getting-started/advanced/fastapi-integration/#integration-testing-test-the-full-stack","title":"Integration Testing: Test the Full Stack","text":"<p>For end-to-end testing, you need to test the FastAPI endpoint with an actual worker processing tasks.</p>"},{"location":"getting-started/advanced/fastapi-integration/#synchronous-tests","title":"Synchronous Tests","text":"<p>Using FastAPI's <code>TestClient</code> requires running a worker in a background thread:</p> tests/test_app.py<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom sheppy import MemoryBackend, Queue, Worker\nfrom main import app, get_queue\n\n\n@pytest.fixture\ndef backend():\n    return MemoryBackend()\n\n\n@pytest.fixture\ndef queue(backend):\n    return Queue(backend, \"pytest\")\n\n\n@pytest.fixture\ndef worker(backend):\n    w = Worker(\"pytest\", backend)\n    # speed up tests (temporary solution)\n    w._blocking_timeout = 0.01\n    w._scheduler_polling_interval = 0.01\n    w._cron_polling_interval = 0.01\n    return w\n\n\ndef test_fastapi_send_email_route(queue, worker):\n\n    app.dependency_overrides[get_queue] = lambda: queue\n\n    with TestClient(app) as client:\n        # run worker process (temporary solution)\n        client.portal.start_task_soon(\n            lambda: worker.work(max_tasks=1, register_signal_handlers=False)\n        )\n\n        # Define email data\n        email_data = {\n            \"to\": \"test@example.com\",\n            \"subject\": \"Welcome Email\",\n            \"body\": \"Hello, pytest!\"\n        }\n\n        response = client.post(\"/send-email\", json=email_data)\n\n        assert response.status_code == 200\n        assert response.json() == {\"ok\": True}\n</code></pre> <p>Note</p> <p>Work in Progress - future versions will provide simpler testing utilities for FastAPI.</p>"},{"location":"getting-started/advanced/fastapi-integration/#async-tests-recommended","title":"Async Tests (Recommended)","text":"<p>For async test suites, use <code>httpx.AsyncClient</code> with <code>asyncio.create_task</code> for cleaner worker management:</p> tests/test_app_async.py<pre><code>import asyncio\nimport pytest\nfrom httpx import ASGITransport, AsyncClient\nfrom sheppy import MemoryBackend, Queue, Worker\nfrom main import app, get_queue\n\n\n@pytest.fixture\ndef backend():\n    return MemoryBackend()\n\n\n@pytest.fixture\ndef queue(backend):\n    return Queue(backend, \"pytest\")\n\n\n@pytest.fixture\ndef worker(backend):\n    w = Worker(\"pytest\", backend)\n    # speed up tests (temporary solution)\n    w._blocking_timeout = 0.01\n    w._scheduler_polling_interval = 0.01\n    w._cron_polling_interval = 0.01\n    return w\n\n\nasync def test_fastapi_send_email_route(queue, worker):\n    # start worker process\n    asyncio.create_task(worker.work(max_tasks=1, register_signal_handlers=False))\n\n    # override queue dependency\n    app.dependency_overrides[get_queue] = lambda: queue\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app), base_url=\"http://test\"\n    ) as client:\n        # Define email data\n        email_data = {\n            \"to\": \"test@example.com\",\n            \"subject\": \"Welcome Email\",\n            \"body\": \"Hello, pytest!\"\n        }\n\n        response = await client.post(\"/send-email\", json=email_data)\n\n        assert response.status_code == 200\n        assert response.json() == {\"ok\": True}\n</code></pre>"},{"location":"reference/cli/","title":"Sheppy CLI reference","text":"<p>Sheppy - Modern Task Queue</p> <p>Usage:</p> <pre><code>$ sheppy [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--version</code>: Show the version and exit.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>work</code>: Start a worker to process tasks from a queue.</li> <li><code>task</code>: Task management commands</li> <li><code>queue</code>: Queue management commands</li> <li><code>cron</code>: Cron management commands</li> </ul>"},{"location":"reference/cli/#sheppy-work","title":"<code>sheppy work</code>","text":"<p>Start a worker to process tasks from a queue.</p> <p>Usage:</p> <pre><code>$ sheppy work [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-q, --queue TEXT</code>: Name of queue to process (can be used multiple times)  [default: default]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>-c, --max-concurrent INTEGER RANGE</code>: Max concurrent tasks  [default: 10; x&gt;=1]</li> <li><code>--reload</code>: Reload worker on file changes</li> <li><code>--oneshot</code>: Process pending tasks and then exit</li> <li><code>--max-tasks INTEGER RANGE</code>: Maximum amount of tasks to process  [x&gt;=1]</li> <li><code>--disable-job-processing</code>: Disable job processing</li> <li><code>--disable-scheduler</code>: Disable scheduler</li> <li><code>--disable-cron-manager</code>: Disable cron manager</li> <li><code>-l, --log-level [debug|info|warning|error]</code>: Logging level  [default: info]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-task","title":"<code>sheppy task</code>","text":"<p>Task management commands</p> <p>Usage:</p> <pre><code>$ sheppy task [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>list</code>: List all tasks.</li> <li><code>info</code>: Get detailed information about a specific...</li> <li><code>retry</code>: Retry a failed task by re-queueing it.</li> <li><code>test</code>: Test run a task function without queuing it.</li> <li><code>add</code>: Add a new task to a queue.</li> <li><code>schedule</code>: Schedule a task to run at a specific time.</li> </ul>"},{"location":"reference/cli/#sheppy-task-list","title":"<code>sheppy task list</code>","text":"<p>List all tasks.</p> <p>Usage:</p> <pre><code>$ sheppy task list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-q, --queue TEXT</code>: Name of queue  [default: default]</li> <li><code>-s, --status [all|pending|scheduled|completed|failed]</code>: Filter by status  [default: all]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>-f, --format [table|json]</code>: Output format  [default: table]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-task-info","title":"<code>sheppy task info</code>","text":"<p>Get detailed information about a specific task.</p> <p>Usage:</p> <pre><code>$ sheppy task info [OPTIONS] TASK_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>TASK_ID</code>: Task ID to get info for  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-q, --queue TEXT</code>: Name of queue  [default: default]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-task-retry","title":"<code>sheppy task retry</code>","text":"<p>Retry a failed task by re-queueing it.</p> <p>Usage:</p> <pre><code>$ sheppy task retry [OPTIONS] TASK_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>TASK_ID</code>: Task ID to retry  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-q, --queue TEXT</code>: Name of queue  [default: default]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>-f, --force</code>: Force retry even if task hasn't failed</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-task-test","title":"<code>sheppy task test</code>","text":"<p>Test run a task function without queuing it.</p> <p>Usage:</p> <pre><code>$ sheppy task test [OPTIONS] FUNCTION\n</code></pre> <p>Arguments:</p> <ul> <li><code>FUNCTION</code>: Function to test (module:function format)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-a, --args TEXT</code>: JSON array of positional arguments  [default: []]</li> <li><code>-k, --kwargs TEXT</code>: JSON object of keyword arguments  [default: {}]</li> <li><code>-t, --trace</code>: Show full execution trace</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-task-add","title":"<code>sheppy task add</code>","text":"<p>Add a new task to a queue.</p> <p>Usage:</p> <pre><code>$ sheppy task add [OPTIONS] FUNCTION\n</code></pre> <p>Arguments:</p> <ul> <li><code>FUNCTION</code>: Function to add (module:function format)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-a, --args TEXT</code>: JSON array of positional arguments  [default: []]</li> <li><code>-k, --kwargs TEXT</code>: JSON object of keyword arguments  [default: {}]</li> <li><code>-w, --wait</code>: Wait for task result</li> <li><code>-t, --timeout FLOAT</code>: Timeout in seconds when waiting for result  [default: 0.0]</li> <li><code>-q, --queue TEXT</code>: Name of queue  [default: default]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-task-schedule","title":"<code>sheppy task schedule</code>","text":"<p>Schedule a task to run at a specific time.</p> <p>Usage:</p> <pre><code>$ sheppy task schedule [OPTIONS] FUNCTION\n</code></pre> <p>Arguments:</p> <ul> <li><code>FUNCTION</code>: Function to schedule (module:function format  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-d, --delay TEXT</code>: Delay before task execution (e.g., 30s, 5m, 2h, 1d)</li> <li><code>--at TEXT</code>: Execute at specific time (ISO format: 2024-01-20T15:30:00)</li> <li><code>-a, --args TEXT</code>: JSON array of positional arguments  [default: []]</li> <li><code>-k, --kwargs TEXT</code>: JSON object of keyword arguments  [default: {}]</li> <li><code>-q, --queue TEXT</code>: Name of queue  [default: default]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-queue","title":"<code>sheppy queue</code>","text":"<p>Queue management commands</p> <p>Usage:</p> <pre><code>$ sheppy queue [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>list</code>: List all queues with their pending task...</li> </ul>"},{"location":"reference/cli/#sheppy-queue-list","title":"<code>sheppy queue list</code>","text":"<p>List all queues with their pending task counts.</p> <p>Usage:</p> <pre><code>$ sheppy queue list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/cli/#sheppy-cron","title":"<code>sheppy cron</code>","text":"<p>Cron management commands</p> <p>Usage:</p> <pre><code>$ sheppy cron [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>list</code>: List all active crons.</li> </ul>"},{"location":"reference/cli/#sheppy-cron-list","title":"<code>sheppy cron list</code>","text":"<p>List all active crons.</p> <p>Usage:</p> <pre><code>$ sheppy cron list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-q, --queue TEXT</code>: Name of queue  [default: default]</li> <li><code>-b, --backend [redis]</code>: Queue backend type  [default: redis]</li> <li><code>-r, --redis-url TEXT</code>: Redis server URL  [default: redis://127.0.0.1:6379]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/queue/","title":"<code>Queue</code> reference","text":"<p>Sheppy provides a <code>Queue</code> class to manage and execute background tasks. The queue supports adding tasks, scheduling them for future execution, retrying failed tasks, and managing periodic tasks using cron expressions.</p> <p>See Getting Started guide for more details and examples.</p>"},{"location":"reference/queue/#sheppy.Queue","title":"sheppy.Queue","text":"<pre><code>Queue(backend: Backend, name: str = 'default')\n</code></pre> <p><code>Queue</code> class provides an easy way to manage task queue.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of task backend (e.g. <code>sheppy.RedisBackend</code>)</p> <p> TYPE: <code>Backend</code> </p> <code>name</code> <p>Name of the queue</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> Source code in <code>src/sheppy/queue.py</code> <pre><code>def __init__(self, backend: Backend, name: str = \"default\"):\n    self.name = name\n    self.backend = backend\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.add","title":"add","text":"<pre><code>add(task: Task) -&gt; bool\n</code></pre><pre><code>add(task: list[Task]) -&gt; list[bool]\n</code></pre> <p>Add task into the queue. Accept list of tasks for batch add.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task, or list of Task instances for batch mode.</p> <p> TYPE: <code>Task | list[Task]</code> </p> RETURNS DESCRIPTION <code>bool | list[bool]</code> <p>Success boolean, or list of booleans in batch mode.</p> Example <pre><code>q = Queue(...)\nsuccess = await q.add(task)\nassert success is True\n\n# batch mode\nsuccess = await q.add([task1, task2])\nassert success == [True, True]  # returns list of booleans in batch mode\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def add(self, task: Task | list[Task]) -&gt; bool | list[bool]:\n    \"\"\"\n    Add task into the queue. Accept list of tasks for batch add.\n\n    Args:\n        task: Instance of a Task, or list of Task instances for batch mode.\n\n    Returns:\n        Success boolean, or list of booleans in batch mode.\n\n    Example:\n        ```python\n        q = Queue(...)\n        success = await q.add(task)\n        assert success is True\n\n        # batch mode\n        success = await q.add([task1, task2])\n        assert success == [True, True]  # returns list of booleans in batch mode\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n\n    if isinstance(task, list):\n        batch_mode = True\n        tasks = [t.model_dump(mode='json') for t in task]\n    else:\n        batch_mode = False\n        tasks = [task.model_dump(mode='json')]\n\n    success = await self.backend.append(self.name, tasks)\n\n    return success if batch_mode else success[0]\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.schedule","title":"schedule","text":"<pre><code>schedule(task: Task, at: datetime | timedelta) -&gt; bool\n</code></pre> <p>Schedule task to be processed after certain time.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task</p> <p> TYPE: <code>Task</code> </p> <code>at</code> <p>When to process the task.                        If timedelta is provided, it will be added to current time. Note: datetime must be offset-aware (i.e. have timezone info).</p> <p> TYPE: <code>datetime | timedelta</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> Example <pre><code>from datetime import datetime, timedelta\n\nq = Queue(...)\n# schedule task to be processed after 10 minutes\nawait q.schedule(task, timedelta(minutes=10))\n\n# ... or at specific time\nawait q.schedule(task, datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def schedule(self, task: Task, at: datetime | timedelta) -&gt; bool:\n    \"\"\"Schedule task to be processed after certain time.\n\n    Args:\n        task (Task): Instance of a Task\n        at (datetime | timedelta): When to process the task.&lt;br&gt;\n                                   If timedelta is provided, it will be added to current time.&lt;br&gt;\n                                   *Note: datetime must be offset-aware (i.e. have timezone info).*\n\n    Returns:\n        Success boolean\n\n    Example:\n        ```python\n        from datetime import datetime, timedelta\n\n        q = Queue(...)\n        # schedule task to be processed after 10 minutes\n        await q.schedule(task, timedelta(minutes=10))\n\n        # ... or at specific time\n        await q.schedule(task, datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n\n    if isinstance(at, timedelta):\n        at = datetime.now(timezone.utc) + at\n\n    if not at.tzinfo:\n        raise TypeError(\"provided datetime must be offset-aware\")\n\n    task.__dict__[\"scheduled_at\"] = at\n\n    return await self.backend.schedule(self.name, task.model_dump(mode=\"json\"), at)\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.get_task","title":"get_task","text":"<pre><code>get_task(task: Task | UUID | str) -&gt; Task | None\n</code></pre><pre><code>get_task(task: list[Task | UUID | str]) -&gt; dict[UUID, Task]\n</code></pre> <p>Get task by id.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task or its ID, or list of Task instances/IDs for batch mode.</p> <p> TYPE: <code>Task | UUID | str | list[Task | UUID | str]</code> </p> RETURNS DESCRIPTION <code>Task | None</code> <p>Instance of a Task or None if not found.</p> <code>dict[UUID, Task]</code> <p>(In batch mode) Returns Dictionary of Task IDs to Task instances.</p> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def get_task(self, task: Task | UUID | str | list[Task | UUID | str]) -&gt; dict[UUID, Task] | Task | None:\n    \"\"\"Get task by id.\n\n    Args:\n        task: Instance of a Task or its ID, or list of Task instances/IDs for batch mode.\n\n    Returns:\n        (Task|None): Instance of a Task or None if not found.\n        (dict[UUID, Task]): *(In batch mode)* Returns Dictionary of Task IDs to Task instances.\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n\n    task_ids, batch_mode = self._get_task_ids(task)\n    task_results = await self.backend.get_tasks(self.name, task_ids)\n\n    if batch_mode:\n        return {UUID(t_id): Task.model_validate(t) for t_id, t in task_results.items()}\n\n    td = task_results.get(task_ids[0])\n\n    return Task.model_validate(td) if td else None\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.wait_for","title":"wait_for","text":"<pre><code>wait_for(\n    task: Task | UUID | str, timeout: float = 0\n) -&gt; Task | None\n</code></pre><pre><code>wait_for(\n    task: list[Task | UUID | str], timeout: float = 0\n) -&gt; dict[UUID, Task]\n</code></pre> <p>Wait for task to complete and return updated task instance.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task or its ID, or list of Task instances/IDs for batch mode.</p> <p> TYPE: <code>Task | UUID | str | list[Task | UUID | str]</code> </p> <code>timeout</code> <p>Maximum time to wait in seconds. Default is 0 (wait indefinitely).      If timeout is reached, returns None (or partial results in batch mode).      In batch mode, this is the maximum time to wait for all tasks to complete.      Note: In non-batch mode, if timeout is reached and no task is found, a TimeoutError is raised.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>dict[UUID, Task] | Task | None</code> <p>Instance of a Task or None if not found or timeout reached.In batch mode, returns dictionary of Task IDs to Task instances (partial results possible on timeout).</p> RAISES DESCRIPTION <code>TimeoutError</code> <p>If timeout is reached and no task is found (only in non-batch mode).</p> Example <pre><code>q = Queue(...)\n\n# wait indefinitely for task to complete\nupdated_task = await q.wait_for(task)\nassert updated_task.completed is True\n\n# wait up to 5 seconds for task to complete\ntry:\n    updated_task = await q.wait_for(task, timeout=5)\n    if updated_task:\n        assert updated_task.completed is True\n    else:\n        print(\"Task not found or still pending after timeout\")\nexcept TimeoutError:\n    print(\"Task did not complete within timeout\")\n\n# batch mode\nupdated_tasks = await q.wait_for([task1, task2, task3], timeout=10)\n\nfor task_id, task in updated_tasks.items():\n    print(f\"Task {task_id} completed: {task.completed}\")\n\n# Note: updated_tasks may contain only a subset of tasks if timeout is reached\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def wait_for(self, task: Task | UUID | str | list[Task | UUID | str], timeout: float = 0) -&gt; dict[UUID, Task] | Task | None:\n    \"\"\"Wait for task to complete and return updated task instance.\n\n    Args:\n        task: Instance of a Task or its ID, or list of Task instances/IDs for batch mode.\n        timeout: Maximum time to wait in seconds. Default is 0 (wait indefinitely).&lt;br&gt;\n                 If timeout is reached, returns None (or partial results in batch mode).&lt;br&gt;\n                 In batch mode, this is the maximum time to wait for all tasks to complete.&lt;br&gt;\n                 Note: In non-batch mode, if timeout is reached and no task is found, a TimeoutError is raised.\n\n    Returns:\n        Instance of a Task or None if not found or timeout reached.&lt;br&gt;In batch mode, returns dictionary of Task IDs to Task instances (partial results possible on timeout).\n\n    Raises:\n        TimeoutError: If timeout is reached and no task is found (only in non-batch mode).\n\n    Example:\n        ```python\n        q = Queue(...)\n\n        # wait indefinitely for task to complete\n        updated_task = await q.wait_for(task)\n        assert updated_task.completed is True\n\n        # wait up to 5 seconds for task to complete\n        try:\n            updated_task = await q.wait_for(task, timeout=5)\n            if updated_task:\n                assert updated_task.completed is True\n            else:\n                print(\"Task not found or still pending after timeout\")\n        except TimeoutError:\n            print(\"Task did not complete within timeout\")\n\n        # batch mode\n        updated_tasks = await q.wait_for([task1, task2, task3], timeout=10)\n\n        for task_id, task in updated_tasks.items():\n            print(f\"Task {task_id} completed: {task.completed}\")\n\n        # Note: updated_tasks may contain only a subset of tasks if timeout is reached\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n\n    task_ids, batch_mode = self._get_task_ids(task)\n    task_results = await self.backend.get_results(self.name, task_ids, timeout)\n\n    if batch_mode:\n        return {UUID(t_id): Task.model_validate(t) for t_id, t in task_results.items()}\n\n    td = task_results.get(task_ids[0])\n\n    return Task.model_validate(td) if td else None\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.get_all_tasks","title":"get_all_tasks","text":"<pre><code>get_all_tasks() -&gt; list[Task]\n</code></pre> <p>Get all tasks, including completed/failed ones.</p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of all tasks</p> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def get_all_tasks(self) -&gt; list[Task]:\n    \"\"\"Get all tasks, including completed/failed ones.\n\n    Returns:\n        List of all tasks\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n    tasks_data = await self.backend.get_all_tasks(self.name)\n    return [Task.model_validate(t) for t in tasks_data]\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.get_scheduled","title":"get_scheduled","text":"<pre><code>get_scheduled() -&gt; list[Task]\n</code></pre> <p>List scheduled tasks.</p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of scheduled tasks</p> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def get_scheduled(self) -&gt; list[Task]:\n    \"\"\"List scheduled tasks.\n\n    Returns:\n        List of scheduled tasks\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n    return [Task.model_validate(t) for t in await self.backend.get_scheduled(self.name)]\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.get_pending","title":"get_pending","text":"<pre><code>get_pending(count: int = 1) -&gt; list[Task]\n</code></pre> <p>List pending tasks.</p> PARAMETER DESCRIPTION <code>count</code> <p>Number of pending tasks to retrieve.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of pending tasks</p> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def get_pending(self, count: int = 1) -&gt; list[Task]:\n    \"\"\"List pending tasks.\n\n    Args:\n        count: Number of pending tasks to retrieve.\n\n    Returns:\n        List of pending tasks\n    \"\"\"\n    if count &lt;= 0:\n        raise ValueError(\"Value must be larger than zero\")\n\n    await self.__ensure_backend_is_connected()\n\n    return [Task.model_validate(t) for t in await self.backend.get_pending(self.name, count)]\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.retry","title":"retry","text":"<pre><code>retry(\n    task: Task | UUID | str,\n    at: datetime | timedelta | None = None,\n    force: bool = False,\n) -&gt; bool\n</code></pre> <p>Retry failed task.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task or its ID</p> <p> TYPE: <code>Task | UUID | str</code> </p> <code>at</code> <p>When to retry the task. - If None (default), retries immediately. - If timedelta is provided, it will be added to current time. Note: datetime must be offset-aware (i.e. have timezone info).</p> <p> TYPE: <code>datetime | timedelta | None</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>If True, allows retrying even if task has completed successfully. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> RAISES DESCRIPTION <code>ValueError</code> <p>If task has already completed successfully and force is not set to True.</p> <code>TypeError</code> <p>If provided datetime is not offset-aware.</p> Example <pre><code>q = Queue(...)\n\n# retry task immediately\nsuccess = await q.retry(task)\nassert success is True\n\n# or retry after 5 minutes\nawait q.retry(task, at=timedelta(minutes=5))\n\n# or at specific time\nawait q.retry(task, at=datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n\n# force retry even if task is completed (= finished successfully)\nawait q.retry(task, force=True)\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def retry(self, task: Task | UUID | str, at: datetime | timedelta | None = None, force: bool = False) -&gt; bool:\n    \"\"\"Retry failed task.\n\n    Args:\n        task: Instance of a Task or its ID\n        at: When to retry the task.&lt;br&gt;\n            - If None (default), retries immediately.&lt;br&gt;\n            - If timedelta is provided, it will be added to current time.&lt;br&gt;\n            *Note: datetime must be offset-aware (i.e. have timezone info).*\n        force: If True, allows retrying even if task has completed successfully. Defaults to False.\n\n    Returns:\n        Success boolean\n\n    Raises:\n        ValueError: If task has already completed successfully and force is not set to True.\n        TypeError: If provided datetime is not offset-aware.\n\n    Example:\n        ```python\n        q = Queue(...)\n\n        # retry task immediately\n        success = await q.retry(task)\n        assert success is True\n\n        # or retry after 5 minutes\n        await q.retry(task, at=timedelta(minutes=5))\n\n        # or at specific time\n        await q.retry(task, at=datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n\n        # force retry even if task is completed (= finished successfully)\n        await q.retry(task, force=True)\n        ```\n    \"\"\"\n    _task = await self.get_task(task)  # ensure_backend_is_connected is called in get_task already\n    if not _task:\n        return False\n\n    if not force and _task.completed:\n        raise ValueError(\"Task has already completed successfully, use force to retry anyways\")\n\n    needs_update = False  # temp hack\n    if _task.finished_at:\n        needs_update = True\n        _task.__dict__[\"last_retry_at\"] = datetime.now(timezone.utc)\n        _task.__dict__[\"next_retry_at\"] = datetime.now(timezone.utc)\n        _task.__dict__[\"finished_at\"] = None\n\n    if at:\n        if isinstance(at, timedelta):\n            at = datetime.now(timezone.utc) + at\n\n        if not at.tzinfo:\n            raise TypeError(\"provided datetime must be offset-aware\")\n\n        if needs_update:\n            _task.__dict__[\"next_retry_at\"] = at\n            _task.__dict__[\"scheduled_at\"] = at\n\n        return await self.backend.schedule(self.name, _task.model_dump(mode=\"json\"), at, unique=False)\n\n    success = await self.backend.append(self.name, [_task.model_dump(mode=\"json\")], unique=False)\n    return success[0]\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.size","title":"size","text":"<pre><code>size() -&gt; int\n</code></pre> <p>Get number of pending tasks in the queue.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of pending tasks</p> Example <pre><code>q = Queue(...)\n\nawait q.add(task)\n\ncount = await q.size()\nassert count == 1\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def size(self) -&gt; int:\n    \"\"\"Get number of pending tasks in the queue.\n\n    Returns:\n        Number of pending tasks\n\n    Example:\n        ```python\n        q = Queue(...)\n\n        await q.add(task)\n\n        count = await q.size()\n        assert count == 1\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n    return await self.backend.size(self.name)\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.clear","title":"clear","text":"<pre><code>clear() -&gt; int\n</code></pre> <p>Clear all tasks, including completed ones.</p> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def clear(self) -&gt; int:\n    \"\"\"Clear all tasks, including completed ones.\"\"\"\n    await self.__ensure_backend_is_connected()\n    return await self.backend.clear(self.name)\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.add_cron","title":"add_cron","text":"<pre><code>add_cron(task: Task, cron: str) -&gt; bool\n</code></pre> <p>Add a cron job to run a task on a schedule.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task</p> <p> TYPE: <code>Task</code> </p> <code>cron</code> <p>Cron expression string (e.g. \"*/5 * * * *\" to run every 5 minutes)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> Example <pre><code>q = Queue(...)\n\n@task\nasync def say_hello(to: str) -&gt; str:\n    print(f\"[{datetime.now()}] Hello, {to}!\")\n\n# schedule task to run every minute\nawait q.add_cron(say_hello(\"World\"), \"* * * * *\")\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def add_cron(self, task: Task, cron: str) -&gt; bool:\n    \"\"\"Add a cron job to run a task on a schedule.\n\n    Args:\n        task: Instance of a Task\n        cron: Cron expression string (e.g. \"*/5 * * * *\" to run every 5 minutes)\n\n    Returns:\n        Success boolean\n\n    Example:\n        ```python\n        q = Queue(...)\n\n        @task\n        async def say_hello(to: str) -&gt; str:\n            print(f\"[{datetime.now()}] Hello, {to}!\")\n\n        # schedule task to run every minute\n        await q.add_cron(say_hello(\"World\"), \"* * * * *\")\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n    task_cron = TaskFactory.create_cron_from_task(task, cron)\n    return await self.backend.add_cron(self.name, str(task_cron.deterministic_id), task_cron.model_dump(mode=\"json\"))\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.delete_cron","title":"delete_cron","text":"<pre><code>delete_cron(task: Task, cron: str) -&gt; bool\n</code></pre> <p>Delete a cron job.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task</p> <p> TYPE: <code>Task</code> </p> <code>cron</code> <p>Cron expression string used when adding the cron job</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> Example <pre><code>q = Queue(...)\n\n# delete previously added cron job\nsuccess = await q.delete_cron(say_hello(\"World\"), \"* * * * *\")\nassert success is True\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def delete_cron(self, task: Task, cron: str) -&gt; bool:\n    \"\"\"Delete a cron job.\n\n    Args:\n        task: Instance of a Task\n        cron: Cron expression string used when adding the cron job\n\n    Returns:\n        Success boolean\n\n    Example:\n        ```python\n        q = Queue(...)\n\n        # delete previously added cron job\n        success = await q.delete_cron(say_hello(\"World\"), \"* * * * *\")\n        assert success is True\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n    task_cron = TaskFactory.create_cron_from_task(task, cron)\n    return await self.backend.delete_cron(self.name, str(task_cron.deterministic_id))\n</code></pre>"},{"location":"reference/queue/#sheppy.Queue.get_crons","title":"get_crons","text":"<pre><code>get_crons() -&gt; list[TaskCron]\n</code></pre> <p>List all cron jobs.</p> RETURNS DESCRIPTION <code>list[TaskCron]</code> <p>List of TaskCron instances</p> Example <pre><code>q = Queue(...)\n\ncrons = await q.get_crons()\n\nfor cron in crons:\n    print(f\"Cron ID: {cron.id}, Expression: {cron.expression}, Task Spec: {cron.spec}\")\n</code></pre> Source code in <code>src/sheppy/queue.py</code> <pre><code>async def get_crons(self) -&gt; list[TaskCron]:\n    \"\"\"List all cron jobs.\n\n    Returns:\n        List of TaskCron instances\n\n    Example:\n        ```python\n        q = Queue(...)\n\n        crons = await q.get_crons()\n\n        for cron in crons:\n            print(f\"Cron ID: {cron.id}, Expression: {cron.expression}, Task Spec: {cron.spec}\")\n        ```\n    \"\"\"\n    await self.__ensure_backend_is_connected()\n    return [TaskCron.model_validate(tc) for tc in await self.backend.get_crons(self.name)]\n</code></pre>"},{"location":"reference/task-config/","title":"<code>TaskConfig</code> model reference","text":""},{"location":"reference/task-config/#sheppy.models.Config","title":"sheppy.models.Config","text":"<p>               Bases: <code>BaseModel</code></p> <p>Task configuration</p> ATTRIBUTE DESCRIPTION <code>retry</code> <p>Number of times to retry the task if it fails. Default is 0 (no retries).</p> <p> TYPE: <code>int</code> </p> <code>retry_delay</code> <p>Delay between retries in seconds. If a single float is provided, it will be used for all retries. If a list is provided, it will be used for each retry attempt respectively (exponential backoff). Default is 1.0 seconds.</p> <p> TYPE: <code>float | list[float]</code> </p> Note <ul> <li>You should not create Config instances directly. Instead, use the <code>@task</code> decorator to define a task function, and then call that function to create a Task instance.</li> <li><code>retry</code> must be a non-negative integer.</li> <li><code>retry_delay</code> must be a positive float or a list of positive floats.</li> </ul> Example <pre><code>from sheppy import task\n\n@task(retry=3, retry_delay=[1, 2, 3])\ndef my_task():\n    raise Exception(\"Something went wrong\")\n\nt = my_task()\nprint(t.config.retry)  # 3\nprint(t.config.retry_delay)  # [1.0, 2.0, 3.0]\n</code></pre>"},{"location":"reference/task-config/#sheppy.models.Config.retry","title":"retry","text":"<pre><code>retry: int = Field(default=0, ge=0)\n</code></pre> <p>int: Number of times to retry the task if it fails. Default is 0 (no retries).</p>"},{"location":"reference/task-config/#sheppy.models.Config.retry_delay","title":"retry_delay","text":"<pre><code>retry_delay: float | list[float] = Field(default=1.0)\n</code></pre> <p>float|list[float]: Delay between retries in seconds. If a single float is provided, it will be used for all retries. If a list is provided, it will be used for each retry attempt respectively (exponential backoff). Default is 1.0 seconds.</p>"},{"location":"reference/task-cron/","title":"<code>TaskCron</code> model reference","text":""},{"location":"reference/task-cron/#sheppy.models.TaskCron","title":"sheppy.models.TaskCron","text":"<p>               Bases: <code>BaseModel</code></p> <p>A cron definition that creates tasks on a schedule.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for the cron definition.</p> <p> TYPE: <code>UUID</code> </p> <code>expression</code> <p>Cron expression defining the schedule, e.g. \"*/5 * * * *\" for every 5 minutes.</p> <p> TYPE: <code>str</code> </p> <code>spec</code> <p>Task specification</p> <p> TYPE: <code>Spec</code> </p> <code>config</code> <p>Task configuration</p> <p> TYPE: <code>Config</code> </p> Note <ul> <li>You should not create TaskCron instances directly. Instead, use the <code>add_cron</code> method of the Queue class to create a cron definition.</li> <li><code>args</code> and <code>kwargs</code> in <code>spec</code> must be JSON serializable.</li> </ul> Example <pre><code>from sheppy import Queue, task\n\nq = Queue(...)\n\n@task\ndef say_hello(to: str) -&gt; str:\n    s = f\"Hello, {to}!\"\n    print(s)\n    return s\n\n# add_cron returns bool indicating success\nsuccess = await q.add_cron(say_hello(\"World\"), \"*/5 * * * *\")\nassert success is True\n\n# retrieve all cron jobs\ncrons = await q.get_crons()\nfor cron in crons:\n    print(cron.id)  # UUID of the cron definition\n    print(cron.expression)  # \"*/5 * * * *\"\n    print(cron.spec.func)  # \"my_module:say_hello\"\n    print(cron.spec.args)  # [\"World\"]\n</code></pre>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.id","title":"id","text":"<pre><code>id: UUID = Field(default_factory=uuid4)\n</code></pre> <p>UUID: Unique identifier for the cron definition.</p>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.expression","title":"expression","text":"<pre><code>expression: CronExpression\n</code></pre> <p>str: Cron expression defining the schedule, e.g. \"*/5 * * * *\" for every 5 minutes.</p>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.spec","title":"spec","text":"<pre><code>spec: Spec\n</code></pre> <p>Task specification</p>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.config","title":"config","text":"<pre><code>config: Config\n</code></pre> <p>Task configuration</p>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.deterministic_id","title":"deterministic_id","text":"<pre><code>deterministic_id: UUID\n</code></pre> <p>Deterministic UUID to prevent duplicated cron definitions.</p> <p>This property generates a deterministic UUID for the cron definition based on its spec, config, and expression. This ensures that identical cron definitions always have the same UUID, preventing duplicates.</p> RETURNS DESCRIPTION <code>UUID</code> <p>A deterministic UUID based on the cron definition's spec, config, and expression.</p> <p> TYPE: <code>UUID</code> </p> Example <pre><code>from sheppy import task, Queue\nfrom sheppy.task_factory import TaskFactory\n\n@task\ndef say_hello(to: str) -&gt; None:\n    print(f\"Hello, {to}!\")\n\nq = Queue(...)\nsuccess = await q.add_cron(say_hello(\"World\"), \"*/5 * * * *\")\nassert success is True\n\nsuccess = await q.add_cron(say_hello(\"World\"), \"*/5 * * * *\")\nassert success is False  # duplicate cron definition prevented\n\n# second example\ncron1 = TaskFactory.create_cron_from_task(say_hello(\"World\"), \"*/5 * * * *\")\ncron2 = TaskFactory.create_cron_from_task(say_hello(\"World\"), \"*/5 * * * *\")\nassert cron1.deterministic_id == cron2.deterministic_id\nassert cron1.id != cron2.id  # different random UUIDs\n</code></pre>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.next_run","title":"next_run","text":"<pre><code>next_run(start: datetime | None = None) -&gt; datetime\n</code></pre> <p>Get the next scheduled run time based on the cron expression.</p> PARAMETER DESCRIPTION <code>start</code> <p>The starting point to calculate the next run time. If None, the current UTC time is used.</p> <p> TYPE: <code>datetime | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>datetime</code> <p>The next scheduled run time.</p> <p> TYPE: <code>datetime</code> </p> Source code in <code>src/sheppy/models.py</code> <pre><code>def next_run(self, start: datetime | None = None) -&gt; datetime:\n    \"\"\"Get the next scheduled run time based on the cron expression.\n\n    Args:\n        start (datetime|None): The starting point to calculate the next run time. If None, the current UTC time is used.\n\n    Returns:\n        datetime: The next scheduled run time.\n    \"\"\"\n    if not start:\n        start = datetime.now(timezone.utc)\n    return croniter(self.expression, start).get_next(datetime)\n</code></pre>"},{"location":"reference/task-cron/#sheppy.models.TaskCron.create_task","title":"create_task","text":"<pre><code>create_task(start: datetime) -&gt; Task\n</code></pre> <p>Create a Task instance for the next scheduled run. Used by workers to create tasks based on the cron schedule.</p> <p>The task ID is deterministic based on the cron definition and the scheduled time to prevent duplicates.</p> PARAMETER DESCRIPTION <code>start</code> <p>The scheduled time for the task.</p> <p> TYPE: <code>datetime</code> </p> RETURNS DESCRIPTION <code>Task</code> <p>A new Task instance scheduled to run at the specified time.</p> <p> TYPE: <code>Task</code> </p> Source code in <code>src/sheppy/models.py</code> <pre><code>def create_task(self, start: datetime) -&gt; Task:\n    \"\"\"Create a Task instance for the next scheduled run. Used by workers to create tasks based on the cron schedule.\n\n    The task ID is deterministic based on the cron definition and the scheduled time to prevent duplicates.\n\n    Args:\n        start (datetime): The scheduled time for the task.\n\n    Returns:\n        Task: A new Task instance scheduled to run at the specified time.\n    \"\"\"\n    return Task(\n        id=uuid5(TASK_CRON_NS, str(self.deterministic_id) + str(start.timestamp())),\n        spec=self.spec.model_copy(deep=True),\n        config=self.config.model_copy(deep=True)\n    )\n</code></pre>"},{"location":"reference/task-spec/","title":"<code>TaskSpec</code> model reference","text":""},{"location":"reference/task-spec/#sheppy.models.Spec","title":"sheppy.models.Spec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Task specification.</p> ATTRIBUTE DESCRIPTION <code>func</code> <p>Fully qualified function name, e.g. <code>my_module.my_submodule:my_function</code></p> <p> TYPE: <code>str</code> </p> <code>args</code> <p>Positional arguments to be passed to the function.</p> <p> TYPE: <code>list[Any]</code> </p> <code>kwargs</code> <p>Keyword arguments to be passed to the function.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>return_type</code> <p>Fully qualified return type name, e.g. <code>my_module.submodule:MyPydanticModel</code>. This is used to reconstruct the return value if it's a pydantic model.</p> <p> TYPE: <code>str | None</code> </p> <code>middleware</code> <p>List of fully qualified middleware function names to be applied to the task, e.g. <code>['my_module.submodule:my_middleware']</code>. Middleware will be applied in the order they are listed.</p> <p> TYPE: <code>list[str] | None</code> </p> Note <ul> <li>You should not create Spec instances directly. Instead, use the <code>@task</code> decorator to define a task function, and then call that function to create a Task instance.</li> <li><code>args</code> and <code>kwargs</code> must be JSON serializable.</li> </ul> Example <pre><code>from sheppy import task\n\n@task\ndef my_task(x: int, y: str) -&gt; str:\n    return f\"Received {x} and {y}\"\n\nt = my_task(42, \"hello\")  # returns a Task instance, it is NOT executed yet\n\nprint(t.spec.func)  # e.g. \"my_module:my_task\"\nprint(t.spec.args)  # [42, \"hello\"]\nprint(t.spec.return_type)  # \"builtins.str\"\n</code></pre>"},{"location":"reference/task-spec/#sheppy.models.Spec.func","title":"func","text":"<pre><code>func: str\n</code></pre> <p>str: Fully qualified function name, e.g. <code>my_module.my_submodule:my_function</code></p>"},{"location":"reference/task-spec/#sheppy.models.Spec.args","title":"args","text":"<pre><code>args: list[Any] = Field(default_factory=list)\n</code></pre> <p>list[Any]: Positional arguments to be passed to the function.</p>"},{"location":"reference/task-spec/#sheppy.models.Spec.kwargs","title":"kwargs","text":"<pre><code>kwargs: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <p>dict[str, Any]: Keyword arguments to be passed to the function.</p>"},{"location":"reference/task-spec/#sheppy.models.Spec.return_type","title":"return_type","text":"<pre><code>return_type: str | None = None\n</code></pre> <p>str|None: Fully qualified return type name, e.g. <code>my_module.submodule:MyPydanticModel</code>. This is used to reconstruct the return value if it's a pydantic model.</p>"},{"location":"reference/task-spec/#sheppy.models.Spec.middleware","title":"middleware","text":"<pre><code>middleware: list[str] | None = None\n</code></pre> <p>list[str]|None: List of fully qualified middleware function names to be applied to the task, e.g. <code>['my_module.submodule:my_middleware']</code>. Middleware will be applied in the order they are listed.</p>"},{"location":"reference/task/","title":"<code>Task</code> model reference","text":"<p>Here's the reference information for the <code>Task</code> model, with all its parameters, attributes, and methods.</p>"},{"location":"reference/task/#sheppy.Task","title":"sheppy.Task","text":"<p>               Bases: <code>BaseModel</code></p> <p>A task instance created when a task function is called.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for the task.</p> <p> TYPE: <code>UUID</code> </p> <code>completed</code> <p>A completion flag that is set to True only if task finished successfully.</p> <p> TYPE: <code>bool</code> </p> <code>error</code> <p>Error message if the task failed. None if the task succeeded or is not yet executed.</p> <p> TYPE: <code>str | None</code> </p> <code>result</code> <p>The result of the task execution. If the task failed, this will be None.</p> <p> TYPE: <code>Any</code> </p> <code>spec</code> <p>Task specification</p> <p> TYPE: <code>Spec</code> </p> <code>config</code> <p>Task configuration</p> <p> TYPE: <code>Config</code> </p> <code>created_at</code> <p>Timestamp when the task was created.</p> <p> TYPE: <code>datetime</code> </p> <code>finished_at</code> <p>Timestamp when the task was finished. None if the task is not yet finished.</p> <p> TYPE: <code>datetime | None</code> </p> <code>scheduled_at</code> <p>Timestamp when the task is scheduled to run. None if the task is not scheduled.</p> <p> TYPE: <code>datetime | None</code> </p> <code>retry_count</code> <p>Number of times the task has been retried.</p> <p> TYPE: <code>int</code> </p> <code>last_retry_at</code> <p>Timestamp when the task was last retried. None if the task has never been retried.</p> <p> TYPE: <code>datetime | None</code> </p> <code>next_retry_at</code> <p>Timestamp when the task is scheduled to be retried next. None if the task is not scheduled for retry.</p> <p> TYPE: <code>datetime | None</code> </p> <code>is_retriable</code> <p>Returns True if the task is configured to be retriable.</p> <p> TYPE: <code>bool</code> </p> <code>should_retry</code> <p>Returns True if the task should be retried based on its retry configuration and current retry count.</p> <p> TYPE: <code>bool</code> </p> Note <ul> <li>You should not create Task instances directly. Instead, use the <code>@task</code> decorator to define a task function, and then call that function to create a Task instance.</li> <li><code>args</code> and <code>kwargs</code> in <code>spec</code> must be JSON serializable.</li> </ul> Example <pre><code>from sheppy import task\n\n@task\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n\nt = add(2, 3)\nprint(t.id)  # UUID of the task\nprint(t.spec.func)  # \"my_module:add\"\nprint(t.spec.args)  # [2, 3]\nprint(t.result)  # None (not yet executed)\n</code></pre>"},{"location":"reference/task/#sheppy.Task.id","title":"id","text":"<pre><code>id: UUID = Field(default_factory=uuid4)\n</code></pre> <p>UUID: Unique identifier for the task.</p>"},{"location":"reference/task/#sheppy.Task.completed","title":"completed","text":"<pre><code>completed: bool = False\n</code></pre> <p>bool: A completion flag that is set to True only if task finished successfully.</p>"},{"location":"reference/task/#sheppy.Task.error","title":"error","text":"<pre><code>error: str | None = None\n</code></pre> <p>str|None: Error message if the task failed. None if the task succeeded or is not yet executed.</p>"},{"location":"reference/task/#sheppy.Task.result","title":"result","text":"<pre><code>result: Any = None\n</code></pre> <p>Any: The result of the task execution. This will be None if the task failed or is not yet executed.</p>"},{"location":"reference/task/#sheppy.Task.spec","title":"spec","text":"<pre><code>spec: Spec\n</code></pre> <p>Task specification</p>"},{"location":"reference/task/#sheppy.Task.config","title":"config","text":"<pre><code>config: Config = Field(default_factory=Config)\n</code></pre> <p>Task configuration</p>"},{"location":"reference/task/#sheppy.Task.created_at","title":"created_at","text":"<pre><code>created_at: AwareDatetime = Field(\n    default_factory=lambda: now(utc)\n)\n</code></pre> <p>datetime: Timestamp when the task was created.</p>"},{"location":"reference/task/#sheppy.Task.finished_at","title":"finished_at","text":"<pre><code>finished_at: AwareDatetime | None = None\n</code></pre> <p>datetime|None: Timestamp when the task was finished. None if the task is not yet finished.</p>"},{"location":"reference/task/#sheppy.Task.scheduled_at","title":"scheduled_at","text":"<pre><code>scheduled_at: AwareDatetime | None = None\n</code></pre> <p>datetime|None: Timestamp when the task is scheduled to run. None if the task is not scheduled.</p>"},{"location":"reference/task/#sheppy.Task.retry_count","title":"retry_count","text":"<pre><code>retry_count: int = 0\n</code></pre> <p>int: Number of times the task has been retried.</p>"},{"location":"reference/task/#sheppy.Task.last_retry_at","title":"last_retry_at","text":"<pre><code>last_retry_at: AwareDatetime | None = None\n</code></pre> <p>datetime|None: Timestamp when the task was last retried. None if the task has never been retried.</p>"},{"location":"reference/task/#sheppy.Task.next_retry_at","title":"next_retry_at","text":"<pre><code>next_retry_at: AwareDatetime | None = None\n</code></pre> <p>datetime|None: Timestamp when the task is scheduled to be retried next. None if the task is not scheduled for retry.</p>"},{"location":"reference/task/#sheppy.Task.is_retriable","title":"is_retriable","text":"<pre><code>is_retriable: bool\n</code></pre> <p>Returns True if the task is configured to be retriable.</p>"},{"location":"reference/task/#sheppy.Task.should_retry","title":"should_retry","text":"<pre><code>should_retry: bool\n</code></pre> <p>Returns True if the task should be retried based on its retry configuration and current retry count.</p>"},{"location":"reference/testqueue/","title":"<code>TestQueue</code> reference","text":"<p>Sheppy offers a first class support for testing tasks using the <code>TestQueue</code> class. This class mimics the behavior of a real queue but operates synchronously, making it ideal for predictable and fast unit tests.</p> <p>See Testing tasks guide for more details and examples.</p>"},{"location":"reference/testqueue/#sheppy.TestQueue","title":"sheppy.TestQueue","text":"<pre><code>TestQueue(name: str = 'test-queue')\n</code></pre> <p>A simple in-memory queue for testing purposes.</p> <p>This queue does not require any external services and processes tasks synchronously. It is designed to be used in synchronous tests and follows the same execution flow as a real queue.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the queue. Defaults to \"test-queue\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'test-queue'</code> </p> ATTRIBUTE DESCRIPTION <code>processed_tasks</code> <p>List of tasks that have been processed.</p> <p> TYPE: <code>list[Task]</code> </p> <code>failed_tasks</code> <p>List of tasks that have failed during processing.</p> <p> TYPE: <code>list[Task]</code> </p> Example <pre><code># tests/test_tasks.py\nfrom sheppy import task, TestQueue\nfrom sheppy.testqueue import assert_is_new, assert_is_completed, assert_is_failed\n\n\n@task\nasync def add(x: int, y: int) -&gt; int:\n    return x + y\n\n\n@task\nasync def divide(x: int, y: int) -&gt; float:\n    return x / y\n\n\ndef test_add_task():\n    q = TestQueue()\n\n    t = add(1, 2)\n\n    # use helper function to check task is new\n    assert_is_new(t)\n\n    # add task to the queue\n    success = q.add(t)\n    assert success is True\n\n    # check queue size\n    assert q.size() == 1\n\n    # process the task\n    processed_task = q.process_next()\n\n    # check task is completed\n    assert_is_completed(processed_task)\n    assert processed_task.result == 3\n\n    # check queue size is now zero\n    assert q.size() == 0\n\n\ndef test_failing_task():\n    q = TestQueue()\n\n    t = divide(1, 0)\n\n    # use helper function to check task is new\n    assert_is_new(t)\n\n    # add task to the queue\n    success = q.add(t)\n    assert success is True\n\n    # check queue size\n    assert q.size() == 1\n\n    # process the task\n    processed_task = q.process_next()\n\n    # check task is failed\n    assert_is_failed(processed_task)\n    assert processed_task.result is None\n    assert processed_task.error == \"division by zero\"\n\n    # check queue size is now zero\n    assert q.size() == 0\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def __init__(\n    self,\n    name: str = \"test-queue\",\n    #dependency_overrides: dict[Callable[..., Any], Callable[..., Any]] | None = None  # ! FIXME\n):\n    self.name = name\n\n    self._backend = MemoryBackend()\n    self._backend._connected = True\n    self._queue = Queue(self._backend, self.name)\n    #self._dependency_resolver = DependencyResolver(dependency_overrides)\n    self._worker_id = \"TestQueue\"\n    self._task_processor = TaskProcessor()\n\n    self.processed_tasks: list[Task] = []\n    self.failed_tasks: list[Task] = []\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.add","title":"add","text":"<pre><code>add(task: Task) -&gt; bool\n</code></pre><pre><code>add(task: list[Task]) -&gt; list[bool]\n</code></pre> <p>Add task into the queue. Accept list of tasks for batch add.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task, or list of Task instances for batch mode.</p> <p> TYPE: <code>Task | list[Task]</code> </p> RETURNS DESCRIPTION <code>bool | list[bool]</code> <p>Success boolean, or list of booleans in batch mode.</p> Example <pre><code>q = TestQueue()\n\n# add single task\nsuccess = q.add(task)\nassert success is True\n\n# add multiple tasks\nresults = q.add([task1, task2, task3])\nassert results == [True, True, True]\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def add(self, task: Task | list[Task]) -&gt; bool | list[bool]:\n    \"\"\"\n    Add task into the queue. Accept list of tasks for batch add.\n\n    Args:\n        task: Instance of a Task, or list of Task instances for batch mode.\n\n    Returns:\n        Success boolean, or list of booleans in batch mode.\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        # add single task\n        success = q.add(task)\n        assert success is True\n\n        # add multiple tasks\n        results = q.add([task1, task2, task3])\n        assert results == [True, True, True]\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.add(task))  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.schedule","title":"schedule","text":"<pre><code>schedule(task: Task, at: datetime | timedelta) -&gt; bool\n</code></pre> <p>Schedule task to be processed after certain time.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task</p> <p> TYPE: <code>Task</code> </p> <code>at</code> <p>When to process the task.                        If timedelta is provided, it will be added to current time. Note: datetime must be offset-aware (i.e. have timezone info).</p> <p> TYPE: <code>datetime | timedelta</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> Example <pre><code>q = TestQueue()\n\n# schedule task to be processed after 10 minutes\nsuccess = q.schedule(task, timedelta(minutes=10))\nassert success is True\n\n# ... or at specific time\nq.schedule(task, datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def schedule(self, task: Task, at: datetime | timedelta) -&gt; bool:\n    \"\"\"Schedule task to be processed after certain time.\n\n    Args:\n        task (Task): Instance of a Task\n        at (datetime | timedelta): When to process the task.&lt;br&gt;\n                                   If timedelta is provided, it will be added to current time.&lt;br&gt;\n                                   *Note: datetime must be offset-aware (i.e. have timezone info).*\n\n    Returns:\n        Success boolean\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        # schedule task to be processed after 10 minutes\n        success = q.schedule(task, timedelta(minutes=10))\n        assert success is True\n\n        # ... or at specific time\n        q.schedule(task, datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.schedule(task, at))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.get_task","title":"get_task","text":"<pre><code>get_task(task: Task | UUID | str) -&gt; Task | None\n</code></pre><pre><code>get_task(task: list[Task | UUID | str]) -&gt; dict[UUID, Task]\n</code></pre> <p>Get task by id.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task or its ID, or list of Task instances/IDs for batch mode.</p> <p> TYPE: <code>Task | UUID | str | list[Task | UUID | str]</code> </p> RETURNS DESCRIPTION <code>Task | None</code> <p>Instance of a Task or None if not found.</p> <code>dict[UUID, Task]</code> <p>(In batch mode) Returns Dictionary of Task IDs to Task instances.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def get_task(self, task: Task | UUID | str | list[Task | UUID | str]) -&gt; Task | None | dict[UUID, Task]:\n    \"\"\"Get task by id.\n\n    Args:\n        task: Instance of a Task or its ID, or list of Task instances/IDs for batch mode.\n\n    Returns:\n        (Task|None): Instance of a Task or None if not found.\n        (dict[UUID, Task]): *(In batch mode)* Returns Dictionary of Task IDs to Task instances.\n    \"\"\"\n    return asyncio.run(self._queue.get_task(task))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.get_all_tasks","title":"get_all_tasks","text":"<pre><code>get_all_tasks() -&gt; list[Task]\n</code></pre> <p>Get all tasks, including completed/failed ones.</p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of all tasks</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def get_all_tasks(self) -&gt; list[Task]:\n    \"\"\"Get all tasks, including completed/failed ones.\n\n    Returns:\n        List of all tasks\n    \"\"\"\n    return asyncio.run(self._queue.get_all_tasks())\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.get_scheduled","title":"get_scheduled","text":"<pre><code>get_scheduled() -&gt; list[Task]\n</code></pre> <p>List scheduled tasks.</p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of scheduled tasks</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def get_scheduled(self) -&gt; list[Task]:\n    \"\"\"List scheduled tasks.\n\n    Returns:\n        List of scheduled tasks\n    \"\"\"\n    return asyncio.run(self._queue.get_scheduled())\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.get_pending","title":"get_pending","text":"<pre><code>get_pending(count: int = 1) -&gt; list[Task]\n</code></pre> <p>List pending tasks.</p> PARAMETER DESCRIPTION <code>count</code> <p>Number of pending tasks to retrieve.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of pending tasks</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def get_pending(self, count: int = 1) -&gt; list[Task]:\n    \"\"\"List pending tasks.\n\n    Args:\n        count: Number of pending tasks to retrieve.\n\n    Returns:\n        List of pending tasks\n    \"\"\"\n    return asyncio.run(self._queue.get_pending(count))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.retry","title":"retry","text":"<pre><code>retry(\n    task: Task | UUID | str,\n    at: datetime | timedelta | None = None,\n    force: bool = False,\n) -&gt; bool\n</code></pre> <p>Retry failed task.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task or its ID</p> <p> TYPE: <code>Task | UUID | str</code> </p> <code>at</code> <p>When to retry the task. - If None (default), retries immediately. - If timedelta is provided, it will be added to current time. Note: datetime must be offset-aware (i.e. have timezone info).</p> <p> TYPE: <code>datetime | timedelta | None</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>If True, allows retrying even if task has completed successfully. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> RAISES DESCRIPTION <code>ValueError</code> <p>If task has already completed successfully and force is not set to True.</p> <code>TypeError</code> <p>If provided datetime is not offset-aware.</p> Example <pre><code>q = TestQueue()\n\n# retry immediately\nsuccess = q.retry(task)\nassert success is True\n\n# or retry after 5 minutes\nq.retry(task, at=timedelta(minutes=5))\n\n# or at specific time\nq.retry(task, at=datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n\n# force retry even if task completed successfully\nq.retry(task, force=True)\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def retry(self, task: Task | UUID | str, at: datetime | timedelta | None = None, force: bool = False) -&gt; bool:\n    \"\"\"Retry failed task.\n\n    Args:\n        task: Instance of a Task or its ID\n        at: When to retry the task.&lt;br&gt;\n            - If None (default), retries immediately.&lt;br&gt;\n            - If timedelta is provided, it will be added to current time.&lt;br&gt;\n            *Note: datetime must be offset-aware (i.e. have timezone info).*\n        force: If True, allows retrying even if task has completed successfully. Defaults to False.\n\n    Returns:\n        Success boolean\n\n    Raises:\n        ValueError: If task has already completed successfully and force is not set to True.\n        TypeError: If provided datetime is not offset-aware.\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        # retry immediately\n        success = q.retry(task)\n        assert success is True\n\n        # or retry after 5 minutes\n        q.retry(task, at=timedelta(minutes=5))\n\n        # or at specific time\n        q.retry(task, at=datetime.fromisoformat(\"2026-01-01 00:00:00 +00:00\"))\n\n        # force retry even if task completed successfully\n        q.retry(task, force=True)\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.retry(task, at, force))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.size","title":"size","text":"<pre><code>size() -&gt; int\n</code></pre> <p>Get number of pending tasks in the queue.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of pending tasks</p> Example <pre><code>q = TestQueue()\n\nq.add(task)\n\ncount = q.size()\nassert count == 1\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def size(self) -&gt; int:\n    \"\"\"Get number of pending tasks in the queue.\n\n    Returns:\n        Number of pending tasks\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        q.add(task)\n\n        count = q.size()\n        assert count == 1\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.size())\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.clear","title":"clear","text":"<pre><code>clear() -&gt; int\n</code></pre> <p>Clear all tasks, including completed ones.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def clear(self) -&gt; int:\n    \"\"\"Clear all tasks, including completed ones.\"\"\"\n    return asyncio.run(self._queue.clear())\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.add_cron","title":"add_cron","text":"<pre><code>add_cron(task: Task, cron: str) -&gt; bool\n</code></pre> <p>Add a cron job to run a task on a schedule.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task</p> <p> TYPE: <code>Task</code> </p> <code>cron</code> <p>Cron expression string (e.g. \"*/5 * * * *\" to run every 5 minutes)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> Example <pre><code>q = TestQueue()\n\n@task\nasync def say_hello(to: str) -&gt; str:\n    print(f\"[{datetime.now()}] Hello, {to}!\")\n\n# schedule task to run every minute\nq.add_cron(say_hello(\"World\"), \"* * * * *\")\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def add_cron(self, task: Task, cron: str) -&gt; bool:\n    \"\"\"Add a cron job to run a task on a schedule.\n\n    Args:\n        task: Instance of a Task\n        cron: Cron expression string (e.g. \"*/5 * * * *\" to run every 5 minutes)\n\n    Returns:\n        Success boolean\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        @task\n        async def say_hello(to: str) -&gt; str:\n            print(f\"[{datetime.now()}] Hello, {to}!\")\n\n        # schedule task to run every minute\n        q.add_cron(say_hello(\"World\"), \"* * * * *\")\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.add_cron(task, cron))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.delete_cron","title":"delete_cron","text":"<pre><code>delete_cron(task: Task, cron: str) -&gt; bool\n</code></pre> <p>Delete a cron job.</p> PARAMETER DESCRIPTION <code>task</code> <p>Instance of a Task</p> <p> TYPE: <code>Task</code> </p> <code>cron</code> <p>Cron expression string used when adding the cron job</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Success boolean</p> Example <pre><code>q = TestQueue()\n\n# delete previously added cron job\nsuccess = q.delete_cron(say_hello(\"World\"), \"* * * * *\")\nassert success is True\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def delete_cron(self, task: Task, cron: str) -&gt; bool:\n    \"\"\"Delete a cron job.\n\n    Args:\n        task: Instance of a Task\n        cron: Cron expression string used when adding the cron job\n\n    Returns:\n        Success boolean\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        # delete previously added cron job\n        success = q.delete_cron(say_hello(\"World\"), \"* * * * *\")\n        assert success is True\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.delete_cron(task, cron))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.get_crons","title":"get_crons","text":"<pre><code>get_crons() -&gt; list[TaskCron]\n</code></pre> <p>List all cron jobs.</p> RETURNS DESCRIPTION <code>list[TaskCron]</code> <p>List of TaskCron instances</p> Example <pre><code>q = TestQueue()\n\ncrons = q.get_crons()\n\nfor cron in crons:\n    print(f\"Cron ID: {cron.id}, Expression: {cron.expression}, Task Spec: {cron.spec}\")\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def get_crons(self) -&gt; list[TaskCron]:\n    \"\"\"List all cron jobs.\n\n    Returns:\n        List of TaskCron instances\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        crons = q.get_crons()\n\n        for cron in crons:\n            print(f\"Cron ID: {cron.id}, Expression: {cron.expression}, Task Spec: {cron.spec}\")\n        ```\n    \"\"\"\n    return asyncio.run(self._queue.get_crons())\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.process_next","title":"process_next","text":"<pre><code>process_next() -&gt; Task | None\n</code></pre> <p>Process the next pending task in the queue.</p> RETURNS DESCRIPTION <code>Task | None</code> <p>The processed Task instance, or None if no pending tasks.</p> Example <pre><code>q = TestQueue()\n\nq.add(task)\nprocessed_task = q.process_next()\nassert processed_task is not None\nassert processed_task.completed is True\n</code></pre> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def process_next(self) -&gt; Task | None:\n    \"\"\"Process the next pending task in the queue.\n\n    Returns:\n        The processed Task instance, or None if no pending tasks.\n\n    Example:\n        ```python\n        q = TestQueue()\n\n        q.add(task)\n        processed_task = q.process_next()\n        assert processed_task is not None\n        assert processed_task.completed is True\n        ```\n    \"\"\"\n    async def _process_next_async() -&gt; Task | None:\n        tasks = await self._queue.pop_pending(limit=1)\n        return await self._execute_task(tasks[0]) if tasks else None\n\n    return asyncio.run(_process_next_async())\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.process_all","title":"process_all","text":"<pre><code>process_all() -&gt; list[Task]\n</code></pre> <p>Process all pending tasks in the queue.</p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of processed Task instances.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def process_all(self) -&gt; list[Task]:\n    \"\"\"Process all pending tasks in the queue.\n\n    Returns:\n        List of processed Task instances.\n    \"\"\"\n    processed = []\n\n    while task := self.process_next():\n        processed.append(task)\n\n    return processed\n</code></pre>"},{"location":"reference/testqueue/#sheppy.TestQueue.process_scheduled","title":"process_scheduled","text":"<pre><code>process_scheduled(\n    at: datetime | timedelta | None = None,\n) -&gt; list[Task]\n</code></pre> <p>Process scheduled tasks that are due by the specified time.</p> PARAMETER DESCRIPTION <code>at</code> <p>The cutoff time to process scheduled tasks. - If datetime is provided, tasks scheduled up to that time will be processed. - If timedelta is provided, it will be added to the current time to determine the cutoff time. - If None (default), processes tasks scheduled up to the current time. Note: datetime must be offset-aware (i.e. have timezone info).</p> <p> TYPE: <code>datetime | timedelta | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Task]</code> <p>List of processed Task instances.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def process_scheduled(self, at: datetime | timedelta | None = None) -&gt; list[Task]:\n    \"\"\"Process scheduled tasks that are due by the specified time.\n\n    Args:\n        at (datetime | timedelta | None): The cutoff time to process scheduled tasks.\n            - If datetime is provided, tasks scheduled up to that time will be processed.\n            - If timedelta is provided, it will be added to the current time to determine the cutoff time.\n            - If None (default), processes tasks scheduled up to the current time.\n            *Note: datetime must be offset-aware (i.e. have timezone info).*\n\n    Returns:\n        List of processed Task instances.\n    \"\"\"\n    if isinstance(at, timedelta):\n        at = datetime.now(timezone.utc) + at\n    elif at is None:\n        at = datetime.now(timezone.utc)\n\n    async def _process_scheduled_async(at: datetime) -&gt; list[Task]:\n        tasks = [Task.model_validate(t) for t in await self._backend.pop_scheduled(self.name, at)]\n        return [await self._execute_task(task) for task in tasks]\n\n    return asyncio.run(_process_scheduled_async(at))\n</code></pre>"},{"location":"reference/testqueue/#sheppy.testqueue.assert_is_new","title":"sheppy.testqueue.assert_is_new","text":"<pre><code>assert_is_new(task: Task | None) -&gt; None\n</code></pre> <p>Assert that the task is new (not yet processed). Useful in tests.</p> PARAMETER DESCRIPTION <code>task</code> <p>The task to check.</p> <p> TYPE: <code>Task | None</code> </p> RAISES DESCRIPTION <code>AssertionError</code> <p>If the task is not new.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def assert_is_new(task: Task | None) -&gt; None:\n    \"\"\"Assert that the task is new (not yet processed). Useful in tests.\n\n    Args:\n        task (Task|None): The task to check.\n\n    Raises:\n        AssertionError: If the task is not new.\n    \"\"\"\n    assert task is not None\n    assert isinstance(task, Task)\n\n    assert task.completed is False\n    assert task.error is None\n    assert task.result is None\n    assert task.finished_at is None\n</code></pre>"},{"location":"reference/testqueue/#sheppy.testqueue.assert_is_completed","title":"sheppy.testqueue.assert_is_completed","text":"<pre><code>assert_is_completed(task: Task | None) -&gt; None\n</code></pre> <p>Assert that the task is completed (processed successfully). Useful in tests.</p> PARAMETER DESCRIPTION <code>task</code> <p>The task to check.</p> <p> TYPE: <code>Task | None</code> </p> RAISES DESCRIPTION <code>AssertionError</code> <p>If the task is not completed successfully.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def assert_is_completed(task: Task | None) -&gt; None:\n    \"\"\"Assert that the task is completed (processed successfully). Useful in tests.\n\n    Args:\n        task (Task|None): The task to check.\n\n    Raises:\n        AssertionError: If the task is not completed successfully.\n    \"\"\"\n    assert task is not None\n    assert isinstance(task, Task)\n\n    assert task.completed is True\n    assert task.error is None\n    assert task.finished_at is not None\n</code></pre>"},{"location":"reference/testqueue/#sheppy.testqueue.assert_is_failed","title":"sheppy.testqueue.assert_is_failed","text":"<pre><code>assert_is_failed(task: Task | None) -&gt; None\n</code></pre> <p>Assert that the task has failed (processed with error). Useful in tests.</p> PARAMETER DESCRIPTION <code>task</code> <p>The task to check.</p> <p> TYPE: <code>Task | None</code> </p> RAISES DESCRIPTION <code>AssertionError</code> <p>If the task has not failed.</p> Source code in <code>src/sheppy/testqueue.py</code> <pre><code>def assert_is_failed(task: Task | None) -&gt; None:\n    \"\"\"Assert that the task has failed (processed with error). Useful in tests.\n\n    Args:\n        task (Task|None): The task to check.\n\n    Raises:\n        AssertionError: If the task has not failed.\n    \"\"\"\n    assert task is not None\n    assert isinstance(task, Task)\n\n    assert not task.completed\n    assert task.error is not None\n    assert task.result is None\n\n    if not task.should_retry:\n        assert task.finished_at is not None\n</code></pre>"},{"location":"reference/worker/","title":"<code>Worker</code> class reference","text":"<p>In most cases, you can run worker using CLI command <code>sheppy work</code>. See CLI reference for more details.</p> <p>If you need to run it programmatically, you can use the <code>Worker</code> class.</p> <pre><code>from sheppy import Worker\n\nworker = Worker()\n</code></pre>"},{"location":"reference/worker/#sheppy.Worker","title":"sheppy.Worker","text":"<pre><code>Worker(\n    queue_name: str | list[str],\n    backend: Backend,\n    shutdown_timeout: float = 30.0,\n    max_concurrent_tasks: int = 10,\n    enable_job_processing: bool = True,\n    enable_scheduler: bool = True,\n    enable_cron_manager: bool = True,\n)\n</code></pre> <p>Worker that processes tasks from the queue.</p> <p>The Worker monitors the specified queue(s) for pending tasks and processes them asynchronously. It uses blocking pop operations to efficiently wait for new tasks. The worker can handle multiple tasks concurrently, up to a specified limit. It also handles scheduled tasks and cron jobs.</p> PARAMETER DESCRIPTION <code>queue_name</code> <p>Name of the queue or list of queue names to process tasks from.</p> <p> TYPE: <code>str | list[str]</code> </p> <code>backend</code> <p>Instance of the backend to use for storing and retrieving tasks.</p> <p> TYPE: <code>Backend</code> </p> <code>shutdown_timeout</code> <p>Time in seconds to wait for active tasks to complete during shutdown. Default is 30.0 seconds.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> <code>max_concurrent_tasks</code> <p>Maximum number of tasks to process concurrently. Default is 10.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>enable_job_processing</code> <p>If True, enables job processing. Default is True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>enable_scheduler</code> <p>If True, enables the scheduler to enqueue scheduled tasks. Default is True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>enable_cron_manager</code> <p>If True, enables the cron manager to handle cron jobs. Default is True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> ATTRIBUTE DESCRIPTION <code>queues</code> <p>List of Queue instances corresponding to the specified queue names.</p> <p> TYPE: <code>list[Queue]</code> </p> <code>worker_id</code> <p>Unique identifier for the worker instance.</p> <p> TYPE: <code>str</code> </p> <code>stats</code> <p>Statistics about processed and failed tasks.</p> <p> TYPE: <code>WorkerStats</code> </p> <code>enable_job_processing</code> <p>Indicates if job processing is enabled.</p> <p> TYPE: <code>bool</code> </p> <code>enable_scheduler</code> <p>Indicates if the scheduler is enabled.</p> <p> TYPE: <code>bool</code> </p> <code>enable_cron_manager</code> <p>Indicates if the cron manager is enabled.</p> <p> TYPE: <code>bool</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If none of the processing types (job processing, scheduler, cron manager) are enabled.</p> Example <pre><code>import asyncio\nfrom sheppy import Worker, RedisBackend\n\nasync def main():\n    backend = RedisBackend()\n    worker = Worker(queue_name=\"default\", backend=backend)\n\n    await worker.work()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> Source code in <code>src/sheppy/worker.py</code> <pre><code>def __init__(\n    self,\n    queue_name: str | list[str],\n    backend: Backend,\n    shutdown_timeout: float = 30.0,\n    max_concurrent_tasks: int = 10,\n    enable_job_processing: bool = True,\n    enable_scheduler: bool = True,\n    enable_cron_manager: bool = True,\n):\n    if not any([enable_job_processing, enable_scheduler, enable_cron_manager]):\n        raise ValueError(\"At least one processing type must be enabled\")\n\n    self._backend = backend\n\n    if not isinstance(queue_name, list|tuple):\n        queue_name = [str(queue_name)]\n    self.queues = [Queue(backend, q) for q in queue_name]\n\n    self.shutdown_timeout = shutdown_timeout\n    self.worker_id = generate_unique_worker_id(\"worker\")\n    self.stats = WorkerStats()\n\n    self._task_processor = TaskProcessor()\n    self._task_semaphore = asyncio.Semaphore(max_concurrent_tasks)\n    self._shutdown_event = asyncio.Event()\n    self._ctrl_c_counter = 0\n\n    self._blocking_timeout = 5\n    self._scheduler_polling_interval = 1.0\n    self._cron_polling_interval = 10.0\n\n    self._active_tasks: dict[str, dict[asyncio.Task[Task], Task]] = {queue.name: {} for queue in self.queues}\n\n    self.enable_job_processing = enable_job_processing\n    self.enable_scheduler = enable_scheduler\n    self.enable_cron_manager = enable_cron_manager\n\n    self._work_queue_tasks: list[asyncio.Task[None]] = []\n    self._scheduler_task: asyncio.Task[None] | None = None\n    self._cron_manager_task: asyncio.Task[None] | None = None\n\n    self._tasks_to_process: int | None = None\n    self._empty_queues: list[str] = []\n</code></pre>"},{"location":"reference/worker/#sheppy.Worker.work","title":"work","text":"<pre><code>work(\n    max_tasks: int | None = None,\n    oneshot: bool = False,\n    register_signal_handlers: bool = True,\n) -&gt; None\n</code></pre> <p>Start worker to process tasks from the queue.</p> PARAMETER DESCRIPTION <code>max_tasks</code> <p>Maximum number of tasks to process before shutting down. If None, process indefinitely.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>oneshot</code> <p>If True, process tasks until the queue is empty, then shut down.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>register_signal_handlers</code> <p>If True, register SIGINT and SIGTERM signal handlers for graceful shutdown. Default is True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> RAISES DESCRIPTION <code>BackendError</code> <p>If there is an issue connecting to the backend.</p> Note <ul> <li>The worker can be gracefully shut down by sending a SIGINT or SIGTERM signal (e.g., pressing CTRL+C).</li> <li>If the worker is already shutting down, pressing CTRL+C multiple times (default 3) will force an immediate shutdown.</li> <li>The worker will attempt to complete active tasks before shutting down, up to the specified shutdown timeout.</li> <li>If there are still active tasks after the timeout, they will be cancelled.</li> </ul> Source code in <code>src/sheppy/worker.py</code> <pre><code>async def work(self, max_tasks: int | None = None, oneshot: bool = False, register_signal_handlers: bool = True) -&gt; None:\n    \"\"\"Start worker to process tasks from the queue.\n\n    Args:\n        max_tasks (int | None): Maximum number of tasks to process before shutting down. If None, process indefinitely.\n        oneshot (bool): If True, process tasks until the queue is empty, then shut down.\n        register_signal_handlers (bool): If True, register SIGINT and SIGTERM signal handlers for graceful shutdown. Default is True.\n\n    Returns:\n        None\n\n    Raises:\n        BackendError: If there is an issue connecting to the backend.\n\n    Note:\n        - The worker can be gracefully shut down by sending a SIGINT or SIGTERM signal (e.g., pressing CTRL+C).\n        - If the worker is already shutting down, pressing CTRL+C multiple times (default 3) will force an immediate shutdown.\n        - The worker will attempt to complete active tasks before shutting down, up to the specified shutdown timeout.\n        - If there are still active tasks after the timeout, they will be cancelled.\n    \"\"\"\n    # register signals\n    loop = asyncio.get_event_loop()\n    if register_signal_handlers:\n        self.__register_signal_handlers(loop)\n\n    self._tasks_to_process = max_tasks\n    self._empty_queues.clear()\n\n    # reset state (likely relevant only for tests)\n    self._shutdown_event.clear()\n    self._ctrl_c_counter = 0\n\n    # test connection\n    await self._verify_connection(self._backend)\n\n    # start scheduler\n    if self.enable_scheduler:\n        self._scheduler_task = asyncio.create_task(self._run_scheduler(self._scheduler_polling_interval))\n\n    # start cron manager\n    if self.enable_cron_manager:\n        self._cron_manager_task = asyncio.create_task(self._run_cron_manager(self._cron_polling_interval))\n\n    # start job processing\n    if self.enable_job_processing:\n        for queue in self.queues:\n            self._work_queue_tasks.append(asyncio.create_task(self._run_worker_loop(queue, oneshot)))\n\n    # blocking wait for created asyncio tasks\n    _futures = self._work_queue_tasks\n    _futures += [self._scheduler_task] if self._scheduler_task else []\n    _futures += [self._cron_manager_task] if self._cron_manager_task else []\n    await asyncio.gather(*_futures, return_exceptions=True)\n    self._shutdown_event.set()\n\n    # this is starting to feel like Perl\n    remaining_tasks = {k: v for inner_dict in self._active_tasks.values() for k, v in inner_dict.items()}\n\n    # attempt to exit cleanly\n    if remaining_tasks:\n        logger.info(WORKER_PREFIX + f\"Waiting for {len(remaining_tasks)} active tasks to complete...\")\n        try:\n            await asyncio.wait_for(\n                asyncio.gather(*remaining_tasks.keys(), return_exceptions=True),\n                timeout=self.shutdown_timeout\n            )\n        except asyncio.TimeoutError:\n            logger.warning(\"Some tasks did not complete within shutdown timeout\")\n\n            # ! FIXME - what should we do here with the existing tasks? (maybe DLQ?)\n\n            for task_future in remaining_tasks:\n                if not task_future.done():\n                    task_future.cancel()\n\n                    # ! FIXME - should we try reqeueue here or just store state?\n                    # task = remaining_tasks[task_future]\n                    # try:\n                    #     await queue.add(task)\n                    # except Exception as e:\n                    #     logger.error(f\"Failed to requeue task {task.id}: {e}\", exc_info=True)\n\n    # unregister signals\n    if register_signal_handlers:\n        for sig in (signal.SIGTERM, signal.SIGINT):\n            loop.remove_signal_handler(sig)\n\n    logger.info(f\"Worker stopped. Processed: {self.stats.processed}, Failed: {self.stats.failed}\")\n</code></pre>"},{"location":"reference/worker/#sheppy.worker.WorkerStats","title":"sheppy.worker.WorkerStats","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/worker/#sheppy.worker.WorkerStats.processed","title":"processed","text":"<pre><code>processed: int = 0\n</code></pre>"},{"location":"reference/worker/#sheppy.worker.WorkerStats.failed","title":"failed","text":"<pre><code>failed: int = 0\n</code></pre>"},{"location":"reference/backends/backend/","title":"<code>Backend</code> class reference","text":"<p>In most cases, you don't need to interact with backends directly, as they are used internally by <code>Queue</code>. For usual usage, see the Queue reference and Getting Started guides to learn how to configure and use different backends.</p> <p>If you need to implement a custom backend or want to understand how existing backends work, here's the reference information for the backend classes.</p>"},{"location":"reference/backends/backend/#sheppy.Backend","title":"sheppy.Backend","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"reference/backends/backend/#sheppy.Backend.is_connected","title":"is_connected","text":"<pre><code>is_connected: bool\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.connect","title":"connect","text":"<pre><code>connect() -&gt; None\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def connect(self) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.disconnect","title":"disconnect","text":"<pre><code>disconnect() -&gt; None\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def disconnect(self) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.append","title":"append","text":"<pre><code>append(\n    queue_name: str,\n    tasks: list[dict[str, Any]],\n    unique: bool = True,\n) -&gt; list[bool]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def append(self, queue_name: str, tasks: list[dict[str, Any]], unique: bool = True) -&gt; list[bool]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.pop","title":"pop","text":"<pre><code>pop(\n    queue_name: str,\n    limit: int = 1,\n    timeout: float | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def pop(self, queue_name: str, limit: int = 1, timeout: float | None = None) -&gt; list[dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_tasks","title":"get_tasks","text":"<pre><code>get_tasks(\n    queue_name: str, task_ids: list[str]\n) -&gt; dict[str, dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_tasks(self, queue_name: str, task_ids: list[str]) -&gt; dict[str, dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_all_tasks","title":"get_all_tasks","text":"<pre><code>get_all_tasks(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_all_tasks(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_pending","title":"get_pending","text":"<pre><code>get_pending(\n    queue_name: str, count: int = 1\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_pending(self, queue_name: str, count: int = 1) -&gt; list[dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.schedule","title":"schedule","text":"<pre><code>schedule(\n    queue_name: str,\n    task_data: dict[str, Any],\n    at: datetime,\n    unique: bool = True,\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def schedule(self, queue_name: str, task_data: dict[str, Any], at: datetime, unique: bool = True) -&gt; bool:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_scheduled","title":"get_scheduled","text":"<pre><code>get_scheduled(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_scheduled(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.pop_scheduled","title":"pop_scheduled","text":"<pre><code>pop_scheduled(\n    queue_name: str, now: datetime | None = None\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def pop_scheduled(self, queue_name: str, now: datetime | None = None) -&gt; list[dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.store_result","title":"store_result","text":"<pre><code>store_result(\n    queue_name: str, task_data: dict[str, Any]\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def store_result(self, queue_name: str, task_data: dict[str, Any]) -&gt; bool:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_results","title":"get_results","text":"<pre><code>get_results(\n    queue_name: str,\n    task_ids: list[str],\n    timeout: float | None = None,\n) -&gt; dict[str, dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_results(self, queue_name: str, task_ids: list[str], timeout: float | None = None) -&gt; dict[str, dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.size","title":"size","text":"<pre><code>size(queue_name: str) -&gt; int\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def size(self, queue_name: str) -&gt; int:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.clear","title":"clear","text":"<pre><code>clear(queue_name: str) -&gt; int\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def clear(self, queue_name: str) -&gt; int:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_stats","title":"get_stats","text":"<pre><code>get_stats(queue_name: str) -&gt; dict[str, int]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_stats(self, queue_name: str) -&gt; dict[str, int]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.list_queues","title":"list_queues","text":"<pre><code>list_queues() -&gt; dict[str, int]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def list_queues(self) -&gt; dict[str, int]:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.add_cron","title":"add_cron","text":"<pre><code>add_cron(\n    queue_name: str,\n    deterministic_id: str,\n    task_cron: dict[str, Any],\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def add_cron(self, queue_name: str, deterministic_id: str, task_cron: dict[str, Any]) -&gt; bool:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.delete_cron","title":"delete_cron","text":"<pre><code>delete_cron(queue_name: str, deterministic_id: str) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def delete_cron(self, queue_name: str, deterministic_id: str) -&gt; bool:\n    pass\n</code></pre>"},{"location":"reference/backends/backend/#sheppy.Backend.get_crons","title":"get_crons","text":"<pre><code>get_crons(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/base.py</code> <pre><code>@abstractmethod\nasync def get_crons(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    pass\n</code></pre>"},{"location":"reference/backends/memory-backend/","title":"<code>MemoryBackend</code> class reference","text":"<p>In most cases, you don't need to interact with backends directly, as they are used internally by <code>Queue</code>. For usual usage, see the Queue reference and Getting Started guides to learn how to configure and use different backends.</p> <p>If you need to implement a custom backend or want to understand how existing backends work, here's the reference information for the backend classes.</p>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend","title":"sheppy.MemoryBackend","text":"<pre><code>MemoryBackend()\n</code></pre> <p>               Bases: <code>Backend</code></p> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._task_metadata: dict[str, dict[str, dict[str, Any]]] = defaultdict(dict)  # {QUEUE_NAME: {TASK_ID: task_data}}\n    self._pending: dict[str, list[str]] = defaultdict(list)\n    self._scheduled: dict[str, list[ScheduledTask]] = defaultdict(list)\n    self._crons: dict[str, dict[str, dict[str, Any]]] = defaultdict(dict)\n\n    self._locks: dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)  # for thread-safety\n    self._connected = False\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.is_connected","title":"is_connected","text":"<pre><code>is_connected: bool\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.connect","title":"connect","text":"<pre><code>connect() -&gt; None\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def connect(self) -&gt; None:\n    self._connected = True\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.disconnect","title":"disconnect","text":"<pre><code>disconnect() -&gt; None\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def disconnect(self) -&gt; None:\n    self._connected = False\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.append","title":"append","text":"<pre><code>append(\n    queue_name: str,\n    tasks: list[dict[str, Any]],\n    unique: bool = True,\n) -&gt; list[bool]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def append(self, queue_name: str, tasks: list[dict[str, Any]], unique: bool = True) -&gt; list[bool]:\n    self._check_connected()\n\n    if unique:\n        success = await self._create_tasks(queue_name, tasks)\n        to_queue = [t for i, t in enumerate(tasks) if success[i]]\n    else:\n        success = [True] * len(tasks)\n        to_queue = tasks\n\n    async with self._locks[queue_name]:\n        for task in to_queue:\n            if not unique:\n                self._task_metadata[queue_name][task[\"id\"]] = task\n\n            self._pending[queue_name].append(task[\"id\"])\n\n        return success\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.pop","title":"pop","text":"<pre><code>pop(\n    queue_name: str,\n    limit: int = 1,\n    timeout: float | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def pop(self, queue_name: str, limit: int = 1, timeout: float | None = None) -&gt; list[dict[str, Any]]:\n    self._check_connected()\n\n    start_time = asyncio.get_event_loop().time()\n\n    while True:\n        async with self._locks[queue_name]:\n            if self._pending[queue_name]:\n                tasks = []\n                q = self._pending[queue_name]\n\n                for _ in range(min(limit, len(q))):\n                    task_id = q.pop(0)\n                    task_data = self._task_metadata[queue_name].get(task_id)\n                    if task_data:\n                        tasks.append(task_data)\n\n                return tasks\n\n        if timeout is None or timeout &lt;= 0:\n            return []\n\n        elapsed = asyncio.get_event_loop().time() - start_time\n        if elapsed &gt;= timeout:\n            return []\n\n        await asyncio.sleep(min(0.05, timeout - elapsed))\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_pending","title":"get_pending","text":"<pre><code>get_pending(\n    queue_name: str, count: int = 1\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_pending(self, queue_name: str, count: int = 1) -&gt; list[dict[str, Any]]:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        task_ids = list(self._pending[queue_name])[:count]\n\n        tasks = []\n        for t in task_ids:\n            if task_data := self._task_metadata[queue_name].get(t):\n                tasks.append(task_data)\n\n        return tasks\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.size","title":"size","text":"<pre><code>size(queue_name: str) -&gt; int\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def size(self, queue_name: str) -&gt; int:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        return len(self._pending[queue_name])\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.clear","title":"clear","text":"<pre><code>clear(queue_name: str) -&gt; int\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def clear(self, queue_name: str) -&gt; int:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        queue_size = len(self._task_metadata[queue_name])\n        queue_cron_size = len(self._crons[queue_name])\n\n        self._task_metadata[queue_name].clear()\n        self._pending[queue_name].clear()\n        self._scheduled[queue_name].clear()\n        self._crons[queue_name].clear()\n\n        return queue_size + queue_cron_size\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_tasks","title":"get_tasks","text":"<pre><code>get_tasks(\n    queue_name: str, task_ids: list[str]\n) -&gt; dict[str, dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_tasks(self, queue_name: str, task_ids: list[str]) -&gt; dict[str,dict[str, Any]]:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        results = {}\n        for task_id in task_ids:\n            result = self._task_metadata[queue_name].get(task_id)\n            if result:\n                results[task_id] = result\n\n        return results\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.schedule","title":"schedule","text":"<pre><code>schedule(\n    queue_name: str,\n    task_data: dict[str, Any],\n    at: datetime,\n    unique: bool = True,\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def schedule(self, queue_name: str, task_data: dict[str, Any], at: datetime, unique: bool = True) -&gt; bool:\n    self._check_connected()\n\n    if unique:\n        success = await self._create_tasks(queue_name, [task_data])\n        if not success[0]:\n            return False\n\n    async with self._locks[queue_name]:\n        if not unique:\n            self._task_metadata[queue_name][task_data[\"id\"]] = task_data\n\n        scheduled_task = ScheduledTask(at, task_data[\"id\"])\n        heapq.heappush(self._scheduled[queue_name], scheduled_task)\n\n        return True\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.pop_scheduled","title":"pop_scheduled","text":"<pre><code>pop_scheduled(\n    queue_name: str, now: datetime | None = None\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def pop_scheduled(self, queue_name: str, now: datetime | None = None) -&gt; list[dict[str, Any]]:\n    self._check_connected()\n\n    if now is None:\n        now = datetime.now(timezone.utc)\n\n    async with self._locks[queue_name]:\n        tasks = []\n        scheduled_tasks = self._scheduled[queue_name]\n\n        while scheduled_tasks and scheduled_tasks[0].scheduled_time &lt;= now:\n            scheduled_task = heapq.heappop(scheduled_tasks)\n            task_data = self._task_metadata[queue_name].get(scheduled_task.task_id)\n            if task_data:\n                tasks.append(task_data)\n\n        return tasks\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.store_result","title":"store_result","text":"<pre><code>store_result(\n    queue_name: str, task_data: dict[str, Any]\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def store_result(self, queue_name: str, task_data: dict[str, Any]) -&gt; bool:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        self._task_metadata[queue_name][task_data['id']] = task_data\n\n        return True\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_results","title":"get_results","text":"<pre><code>get_results(\n    queue_name: str,\n    task_ids: list[str],\n    timeout: float | None = None,\n) -&gt; dict[str, dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_results(self, queue_name: str, task_ids: list[str], timeout: float | None = None) -&gt; dict[str,dict[str, Any]]:\n    self._check_connected()\n\n    start_time = asyncio.get_event_loop().time()\n\n    if not task_ids:\n        return {}\n\n    results = {}\n    remaining_ids = task_ids[:]\n\n    while True:\n        async with self._locks[queue_name]:\n            for task_id in task_ids:\n                task_data = self._task_metadata[queue_name].get(task_id, {})\n\n                if task_data.get(\"finished_at\"):\n                    results[task_id] = task_data\n                    remaining_ids.remove(task_id)\n\n        if not remaining_ids:\n            return results\n\n        if timeout is None or timeout &lt; 0:\n            return results\n\n        # endless wait if timeout == 0\n        if timeout == 0:\n            await asyncio.sleep(0.05)\n            continue\n\n        elapsed = asyncio.get_event_loop().time() - start_time\n        if elapsed &gt;= timeout:\n            raise TimeoutError(f\"Did not complete within {timeout} seconds\")\n\n        await asyncio.sleep(min(0.05, timeout - elapsed))\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_stats","title":"get_stats","text":"<pre><code>get_stats(queue_name: str) -&gt; dict[str, int]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_stats(self, queue_name: str) -&gt; dict[str, int]:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        return {\n            \"pending\": len(self._pending[queue_name]),\n            \"completed\": len([t for t in self._task_metadata[queue_name].values() if t[\"finished_at\"]]),\n            \"scheduled\": len(self._scheduled[queue_name]),\n        }\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_all_tasks","title":"get_all_tasks","text":"<pre><code>get_all_tasks(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_all_tasks(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        tasks = self._task_metadata[queue_name]\n        return list(tasks.values())\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.list_queues","title":"list_queues","text":"<pre><code>list_queues() -&gt; dict[str, int]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def list_queues(self) -&gt; dict[str, int]:\n    self._check_connected()\n\n    queues = {}\n    for queue_name in self._task_metadata:\n        async with self._locks[queue_name]:\n            queues[queue_name] = len(self._pending[queue_name])\n\n    return queues\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_scheduled","title":"get_scheduled","text":"<pre><code>get_scheduled(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_scheduled(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        tasks = []\n        for scheduled_task in self._scheduled[queue_name]:\n            task_data = self._task_metadata[queue_name].get(scheduled_task.task_id)\n            if task_data:\n                tasks.append(task_data)\n\n        return tasks\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.add_cron","title":"add_cron","text":"<pre><code>add_cron(\n    queue_name: str,\n    deterministic_id: str,\n    task_cron: dict[str, Any],\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def add_cron(self, queue_name: str, deterministic_id: str, task_cron: dict[str, Any]) -&gt; bool:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        if deterministic_id not in self._crons[queue_name]:\n            self._crons[queue_name][deterministic_id] = task_cron\n            return True\n        return False\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.delete_cron","title":"delete_cron","text":"<pre><code>delete_cron(queue_name: str, deterministic_id: str) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def delete_cron(self, queue_name: str, deterministic_id: str) -&gt; bool:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        if deterministic_id in self._crons[queue_name]:\n            del self._crons[queue_name][deterministic_id]\n            return True\n        return False\n</code></pre>"},{"location":"reference/backends/memory-backend/#sheppy.MemoryBackend.get_crons","title":"get_crons","text":"<pre><code>get_crons(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/memory.py</code> <pre><code>async def get_crons(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    self._check_connected()\n\n    async with self._locks[queue_name]:\n        return list(self._crons[queue_name].values())\n</code></pre>"},{"location":"reference/backends/redis-backend/","title":"<code>RedisBackend</code> class reference","text":"<p>In most cases, you don't need to interact with backends directly, as they are used internally by <code>Queue</code>. For usual usage, see the Queue reference and Getting Started guides to learn how to configure and use different backends.</p> <p>If you need to implement a custom backend or want to understand how existing backends work, here's the reference information for the backend classes.</p>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend","title":"sheppy.RedisBackend","text":"<pre><code>RedisBackend(\n    url: str = \"redis://127.0.0.1:6379\",\n    consumer_group: str = \"workers\",\n    ttl: int | None = 24 * 60 * 60,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>Backend</code></p> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>def __init__(\n    self,\n    url: str = \"redis://127.0.0.1:6379\",\n    consumer_group: str = \"workers\",\n    ttl: int | None = 24 * 60 * 60,  # 24 hours\n    **kwargs: Any\n):\n    self.url = url\n    self.consumer_group = consumer_group\n    self.consumer_name = generate_unique_worker_id(\"consumer\")\n    self.ttl = ttl\n    self.redis_kwargs = kwargs\n\n    self._client: redis.Redis | None = None\n    self._pool: redis.ConnectionPool | None = None\n    self._pending_messages: dict[str, tuple[str, str]] = {}  # task_id -&gt; (queue_name, message_id)\n    self._initialized_groups: set[str] = set()\n    self._results_stream_ttl = 60\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.url","title":"url","text":"<pre><code>url = url\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.consumer_group","title":"consumer_group","text":"<pre><code>consumer_group = consumer_group\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.consumer_name","title":"consumer_name","text":"<pre><code>consumer_name = generate_unique_worker_id('consumer')\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.ttl","title":"ttl","text":"<pre><code>ttl = ttl\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.redis_kwargs","title":"redis_kwargs","text":"<pre><code>redis_kwargs = kwargs\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.is_connected","title":"is_connected","text":"<pre><code>is_connected: bool\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.client","title":"client","text":"<pre><code>client: Redis\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.connect","title":"connect","text":"<pre><code>connect() -&gt; None\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def connect(self) -&gt; None:\n    try:\n        self._pool = redis.ConnectionPool.from_url(\n            self.url,\n            #decode_responses=self.decode_responses,\n            #max_connections=self.max_connections,\n            #protocol=3,  # enable RESP version 3\n            **self.redis_kwargs\n        )\n        self._client = redis.Redis.from_pool(self._pool)\n        await self._client.ping()\n    except Exception as e:\n        self._client = None\n        self._pool = None\n        raise BackendError(f\"Failed to connect to Redis: {e}\") from e\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.disconnect","title":"disconnect","text":"<pre><code>disconnect() -&gt; None\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def disconnect(self) -&gt; None:\n    if self._client:\n        await self._client.aclose()\n        self._client = None\n        self._pool = None\n        self._pending_messages.clear()\n        self._initialized_groups.clear()\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.append","title":"append","text":"<pre><code>append(\n    queue_name: str,\n    tasks: list[dict[str, Any]],\n    unique: bool = True,\n) -&gt; list[bool]\n</code></pre> <p>Add new tasks to be processed.</p> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def append(self, queue_name: str, tasks: list[dict[str, Any]], unique: bool = True) -&gt; list[bool]:\n    \"\"\"Add new tasks to be processed.\"\"\"\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n\n    await self._ensure_consumer_group(pending_tasks_key)\n\n    if unique:\n        success = await self._create_tasks(queue_name, tasks)\n        to_queue = [t for i, t in enumerate(tasks) if success[i]]\n    else:\n        success = [True] * len(tasks)\n        to_queue = tasks\n\n    try:\n        async with self.client.pipeline(transaction=False) as pipe:\n            for t in to_queue:\n                _task_data = json.dumps(t)\n\n                if not unique:\n                    pipe.set(f\"{tasks_metadata_key}:{t['id']}\", _task_data)\n\n                # add to pending stream\n                pipe.xadd(pending_tasks_key, {\"data\": _task_data})\n\n            await pipe.execute()\n    except Exception as e:\n        raise BackendError(f\"Failed to enqueue task: {e}\") from e\n\n    return success\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.pop","title":"pop","text":"<pre><code>pop(\n    queue_name: str,\n    limit: int = 1,\n    timeout: float | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Get next tasks to process. Used primarily by workers.</p> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def pop(self, queue_name: str, limit: int = 1, timeout: float | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"Get next tasks to process. Used primarily by workers.\"\"\"\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n\n    await self._ensure_consumer_group(pending_tasks_key)\n\n    try:\n        result = await self.client.xreadgroup(\n            groupname=self.consumer_group,\n            consumername=self.consumer_name,\n            streams={pending_tasks_key: \"&gt;\"},  # \"&gt;\" means only new messages (not delivered to other consumers)\n            count=limit,\n            block=None if timeout is None or timeout == 0 else int(timeout * 1000)\n        )\n\n        if not result:\n            return []\n\n        messages = result[0][1]  # [['stream-name', [(message_id, dict_data)]]]\n\n        if not messages:\n            return []\n\n        tasks = []\n        for message_id, fields in messages:\n            task_data = json.loads(fields[b\"data\"])\n\n            # store message_id for acknowledge()\n            self._pending_messages[task_data[\"id\"]] = (queue_name, message_id.decode())\n            tasks.append(task_data)\n\n        return tasks\n\n    except Exception as e:\n        raise BackendError(f\"Failed to dequeue task: {e}\") from e\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_pending","title":"get_pending","text":"<pre><code>get_pending(\n    queue_name: str, count: int = 1\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_pending(self, queue_name: str, count: int = 1) -&gt; list[dict[str, Any]]:\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n\n    await self._ensure_consumer_group(pending_tasks_key)\n\n    messages = await self.client.xrange(pending_tasks_key, count=count)\n\n    return [json.loads(fields[b\"data\"]) for _message_id, fields in messages]\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.size","title":"size","text":"<pre><code>size(queue_name: str) -&gt; int\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def size(self, queue_name: str) -&gt; int:\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n\n    await self._ensure_consumer_group(pending_tasks_key)\n\n    return int(await self.client.xlen(pending_tasks_key))\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.clear","title":"clear","text":"<pre><code>clear(queue_name: str) -&gt; int\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def clear(self, queue_name: str) -&gt; int:\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n    scheduled_key = self._scheduled_tasks_key(queue_name)\n\n    await self._ensure_consumer_group(pending_tasks_key)\n\n    keys = await self.client.keys(f\"{tasks_metadata_key}:*\")\n    if not keys:\n        return 0\n\n    count = await self.client.delete(*keys)\n\n    await self.client.xtrim(pending_tasks_key, maxlen=0)\n    await self.client.delete(scheduled_key)\n    # await self.client.delete(tasks_metadata_key)\n\n    return int(count)\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_tasks","title":"get_tasks","text":"<pre><code>get_tasks(\n    queue_name: str, task_ids: list[str]\n) -&gt; dict[str, dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_tasks(self, queue_name: str, task_ids: list[str]) -&gt; dict[str,dict[str, Any]]:\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n\n    if not task_ids:\n        return {}\n\n    task_json = await self.client.mget([f\"{tasks_metadata_key}:{t}\" for t in task_ids])\n    tasks = [json.loads(d) for d in task_json if d]\n\n    return {t['id']: t for t in tasks}\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.schedule","title":"schedule","text":"<pre><code>schedule(\n    queue_name: str,\n    task_data: dict[str, Any],\n    at: datetime,\n    unique: bool = True,\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def schedule(self, queue_name: str, task_data: dict[str, Any], at: datetime, unique: bool = True) -&gt; bool:\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n    scheduled_key = self._scheduled_tasks_key(queue_name)\n\n    if unique:\n        success = await self._create_tasks(queue_name, [task_data])\n        if not success[0]:\n            return False\n\n    try:\n        _task_data = json.dumps(task_data)\n\n        if not unique:\n            await self.client.set(f\"{tasks_metadata_key}:{task_data['id']}\", _task_data)\n\n        # add to sorted set with timestamp as score\n        score = at.timestamp()\n        await self.client.zadd(scheduled_key, {_task_data: score})\n\n        return True\n    except Exception as e:\n        raise BackendError(f\"Failed to schedule task: {e}\") from e\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.pop_scheduled","title":"pop_scheduled","text":"<pre><code>pop_scheduled(\n    queue_name: str, now: datetime | None = None\n) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def pop_scheduled(self, queue_name: str, now: datetime | None = None) -&gt; list[dict[str, Any]]:\n    scheduled_key = self._scheduled_tasks_key(queue_name)\n\n    score = now.timestamp() if now else time()\n\n    task_jsons = await self.client.zrangebyscore(scheduled_key, 0, score)\n\n    tasks = []\n    for task_json in task_jsons:\n        removed = await self.client.zrem(scheduled_key, task_json)\n\n        if removed &lt;= 0:\n            # some other worker already got this task at the same time, skip\n            continue\n\n        tasks.append(json.loads(task_json))\n\n    return tasks\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.store_result","title":"store_result","text":"<pre><code>store_result(\n    queue_name: str, task_data: dict[str, Any]\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def store_result(self, queue_name: str, task_data: dict[str, Any]) -&gt; bool:\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n    finished_tasks_key = self._finished_tasks_key(queue_name)\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n\n    await self._ensure_consumer_group(finished_tasks_key)\n\n    message_id = None\n    if task_data[\"id\"] in self._pending_messages:\n        stored_queue, message_id = self._pending_messages[task_data[\"id\"]]\n\n        if queue_name != stored_queue:  # this should never happen\n            raise BackendError(\"queue name mismatch\")\n\n    try:\n        # trim older messages to keep the stream small\n        min_id = f\"{int((time() - self._results_stream_ttl) * 1000)}-0\"\n\n        async with self.client.pipeline(transaction=True) as pipe:\n            # update task metadata with the results\n            pipe.set(f\"{tasks_metadata_key}:{task_data['id']}\", json.dumps(task_data), ex=self.ttl)\n            # add to finished stream for get_result notifications\n            if task_data[\"finished_at\"] is not None:  #\u00a0only send notification on finished task (for retriable tasks we continue to wait)\n                pipe.xadd(finished_tasks_key, {\"task_id\": task_data[\"id\"]}, minid=min_id)\n            # ack and delete the task from the stream (cleanup)\n            if message_id:\n                pipe.xackdel(pending_tasks_key, self.consumer_group, message_id)\n\n            await (pipe.execute())\n\n        return True\n    except Exception as e:\n        raise BackendError(f\"Failed to store task result: {e}\") from e\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_stats","title":"get_stats","text":"<pre><code>get_stats(queue_name: str) -&gt; dict[str, int]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_stats(self, queue_name: str) -&gt; dict[str, int]:\n    scheduled_tasks_key = self._scheduled_tasks_key(queue_name)\n    pending_tasks_key = self._pending_tasks_key(queue_name)\n    finished_tasks_key = self._finished_tasks_key(queue_name)\n\n    pending = await self.client.xlen(pending_tasks_key)\n    completed = await self.client.xlen(finished_tasks_key)\n\n    return {\n        \"pending\": pending,\n        \"completed\": completed,\n        \"scheduled\": await self.client.zcard(scheduled_tasks_key),\n    }\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_all_tasks","title":"get_all_tasks","text":"<pre><code>get_all_tasks(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_all_tasks(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n\n    keys = await self.client.keys(f\"{tasks_metadata_key}:*\")\n    if not keys:\n        return []\n\n    all_tasks_data = await self.client.mget(keys)\n\n    return [json.loads(task_json) for task_json in all_tasks_data]\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_results","title":"get_results","text":"<pre><code>get_results(\n    queue_name: str,\n    task_ids: list[str],\n    timeout: float | None = None,\n) -&gt; dict[str, dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_results(self, queue_name: str, task_ids: list[str], timeout: float | None = None) -&gt; dict[str,dict[str, Any]]:\n    tasks_metadata_key = self._tasks_metadata_key(queue_name)\n    finished_tasks_key = self._finished_tasks_key(queue_name)\n\n    if not task_ids:\n        return {}\n\n    results = {}\n    remaining_ids = task_ids[:]\n\n    last_id = \"0-0\"\n    if timeout is not None and timeout &gt;= 0:\n        with contextlib.suppress(redis.ResponseError):\n            last_id = (await self.client.xinfo_stream(finished_tasks_key))[\"last-generated-id\"]\n\n    tasks = await self.client.mget([f\"{tasks_metadata_key}:{t}\" for t in task_ids])\n    for task_json in tasks:\n        if not task_json:\n            continue\n        t = json.loads(task_json)\n\n        if t.get(\"finished_at\"):\n             results[t[\"id\"]] = t\n             remaining_ids.remove(t[\"id\"])\n\n    if not remaining_ids:\n        return results\n\n    if timeout is None or timeout &lt; 0:\n        return results\n\n    # endless wait if timeout == 0\n    deadline = None if timeout == 0 else asyncio.get_event_loop().time() + timeout\n\n    while True:\n        if deadline:\n            remaining = deadline - asyncio.get_event_loop().time()\n            if remaining &lt;= 0:\n                raise TimeoutError(f\"Did not complete within {timeout} seconds\")\n        else:\n            remaining = 0\n\n        messages = await self.client.xread(\n            {finished_tasks_key: last_id},\n            block=int(remaining * 1000),\n            count=100\n        )\n\n        if not messages:\n            continue\n\n        for _, stream_messages in messages:\n            for msg_id, data in stream_messages:\n                last_id = msg_id\n                task_id = data.get(b\"task_id\").decode()\n\n                if task_id in remaining_ids:\n                    task_json = await self.client.get(f\"{tasks_metadata_key}:{task_id}\")\n                    if not task_json:\n                        continue\n                    t = json.loads(task_json)\n\n                    if t.get(\"finished_at\"):  # should be always true because we only get notifications for finished tasks\n                        results[t[\"id\"]] = t\n                        remaining_ids.remove(t[\"id\"])\n\n                    if not remaining_ids:\n                        return results\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.list_queues","title":"list_queues","text":"<pre><code>list_queues() -&gt; dict[str, int]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def list_queues(self) -&gt; dict[str, int]:\n\n    queue_names = set()\n\n    for key in await self.client.keys(\"sheppy:*:*\"):\n        queue_names.add(key.decode().split(\":\")[2])\n\n    queues = {}\n    for queue_name in sorted(queue_names):\n        try:\n            pending_count = await self.client.xlen(self._pending_tasks_key(queue_name))\n            queues[queue_name] = int(pending_count)\n        except redis.ResponseError:\n            queues[queue_name] = 0\n\n    return queues\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_scheduled","title":"get_scheduled","text":"<pre><code>get_scheduled(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_scheduled(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    scheduled_key = self._scheduled_tasks_key(queue_name)\n\n    task_jsons = await self.client.zrange(scheduled_key, 0, -1, withscores=True)\n\n    tasks = []\n    for task_json, _score in task_jsons:\n        tasks.append(json.loads(task_json))\n\n    return tasks\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.add_cron","title":"add_cron","text":"<pre><code>add_cron(\n    queue_name: str,\n    deterministic_id: str,\n    task_cron: dict[str, Any],\n) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def add_cron(self, queue_name: str, deterministic_id: str, task_cron: dict[str, Any]) -&gt; bool:\n    cron_tasks_key = self._cron_tasks_key(queue_name)\n    return bool(await self.client.set(f\"{cron_tasks_key}:{deterministic_id}\", json.dumps(task_cron), nx=True))\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.delete_cron","title":"delete_cron","text":"<pre><code>delete_cron(queue_name: str, deterministic_id: str) -&gt; bool\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def delete_cron(self, queue_name: str, deterministic_id: str) -&gt; bool:\n    cron_tasks_key = self._cron_tasks_key(queue_name)\n    return bool(await self.client.delete(f\"{cron_tasks_key}:{deterministic_id}\"))\n</code></pre>"},{"location":"reference/backends/redis-backend/#sheppy.RedisBackend.get_crons","title":"get_crons","text":"<pre><code>get_crons(queue_name: str) -&gt; list[dict[str, Any]]\n</code></pre> Source code in <code>src/sheppy/backend/redis.py</code> <pre><code>async def get_crons(self, queue_name: str) -&gt; list[dict[str, Any]]:\n    cron_tasks_key = self._cron_tasks_key(queue_name)\n    cron_tasks = await self.client.keys(f\"{cron_tasks_key}:*\")\n\n    if not cron_tasks:\n        return []\n\n    return [json.loads(d) for d in await self.client.mget(cron_tasks) if d is not None]\n</code></pre>"}]}